{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aebf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "\n",
    "# ğŸ‘©â€ğŸ’» Author Â  Â : Hyelim Jo (Adapted by Gemini AI)\n",
    "# ğŸ¯ Purpose Â  : AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ v1.0 - Risk Assessor\n",
    "# ğŸ“… Created Â  : 2025-10-23\n",
    "# ğŸ“œ Note Â  Â  Â : risk_assessor.ipynb\n",
    "\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24e81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- Update Log ----------------------------------\n",
    "\n",
    "# 2025-10-23 09:17 / ì´ˆê¸° ìƒì„± / Evidence Collectorì˜ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ë„ë¡ êµ¬ì¡° ì„¤ê³„\n",
    "\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5f7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKAX\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-JIaWGMA_-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# step1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "# Pydanticì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ langchain_coreì—ì„œ Base Model ì„í¬íŠ¸ (langchain v0.2.x ì´ìƒ ê¶Œì¥)\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225d73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ChatOpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# step2. LLM ì´ˆê¸°í™” ë° ì„¤ì • (LLM_MODEL ë° JSON_SCHEMAëŠ” ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2) \n",
    "    print(\"âœ… ChatOpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ChatOpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    llm = None\n",
    "    \n",
    "ASSESSOR_OUTPUT_SCHEMA = {\n",
    "    \"category\": \"string\",\n",
    "    \"risk_level\": \"string (High, Limited, Minimal ì¤‘ íƒ 1)\",\n",
    "    \"assessment_summary\": \"string (í‰ê°€ ê·¼ê±° ë° í•µì‹¬ ì´ìŠˆë¥¼ í•œêµ­ì–´ë¡œ 3ì¤„ ì´ë‚´ ìš”ì•½)\",\n",
    "    \"recommendation_focus\": \"string (Mitigation ì—ì´ì „íŠ¸ê°€ ì§‘ì¤‘í•´ì•¼ í•  êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ (ì˜ˆ: 'ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´', 'ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…ê°€ëŠ¥ì„± ê°•í™”'))\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba1eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3. ë¦¬ìŠ¤í¬ í‰ê°€ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "ASSESSMENT_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \n",
    "         \"ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \"\n",
    "         \"EU AI Act, OECD, UNESCOì™€ ê°™ì€ **Baseline ê·¼ê±°**ì™€ **ìµœì‹  ì‚¬íšŒ ì´ìŠˆ ê·¼ê±°**ì˜ ìš”ì•½ì„ ì¢…í•©í•˜ì—¬, \"\n",
    "         \"ì œê³µëœ ì„œë¹„ìŠ¤ì— ëŒ€í•´ íŠ¹ì • ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬(í¸í–¥ì„±, í”„ë¼ì´ë²„ì‹œ, íˆ¬ëª…ì„± ë“±)ì˜ ìœ„í—˜ë„ë¥¼ íŒë‹¨í•˜ê³ , ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”. \"\n",
    "         \"ìœ„í—˜ë„ëŠ” **High, Limited, Minimal** ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "         \"\\n\\n[ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]:\\n{schema}\"\n",
    "        ),\n",
    "        (\"human\", \n",
    "         \"--- ì„œë¹„ìŠ¤ ë° ë¦¬ìŠ¤í¬ ì •ë³´ ---\"\n",
    "         \"\\nì„œë¹„ìŠ¤ëª…: {service_name}\"\n",
    "         \"\\ní‰ê°€ ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: {category}\"\n",
    "         \"\\n--- Baseline ê·¼ê±° ìš”ì•½ ---\"\n",
    "         \"\\n{baseline_summaries}\"\n",
    "         \"\\n--- Issue ê·¼ê±° ìš”ì•½ ---\"\n",
    "         \"\\n{issue_summaries}\"\n",
    "         \"\\n\\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {service_name}ì˜ {category} ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ì„ í‰ê°€í•˜ê³ , ê°œì„  ê¶Œê³ ì•ˆì˜ ì´ˆì ì„ ì„¤ì •í•˜ì„¸ìš”.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2428a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4. ë¦¬ìŠ¤í¬ í‰ê°€ í•¨ìˆ˜ ì •ì˜ (Stateë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ë„ë¡ ë³€ê²½)\n",
    "def assess_risk_and_update_state(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Stateì—ì„œ ì¦ê±° ë°ì´í„°ë¥¼ ì½ê³  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•œ í›„, Stateì— ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not llm:\n",
    "        print(\"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        state['assessment_status'] = \"Error: LLM failed to initialize.\"\n",
    "        return state\n",
    "    \n",
    "    # ğŸ’¡ Stateì—ì„œ Evidence Collectorì˜ ê²°ê³¼ ì½ê¸°\n",
    "    evidence_data = state.get('evidence_data', {})\n",
    "    if not evidence_data:\n",
    "        print(\"âŒ Stateì— 'evidence_data'ê°€ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        state['assessment_status'] = \"Error: Missing evidence_data in state.\"\n",
    "        return state\n",
    "    \n",
    "    service_name = evidence_data.get('query', 'AI ì„œë¹„ìŠ¤')\n",
    "    risk_categories = list(evidence_data['scores'].keys())\n",
    "    \n",
    "    assessed_risks = []\n",
    "    parser = JsonOutputParser(pydantic_object=None)\n",
    "    \n",
    "    print(f\"\\nâš–ï¸ Risk Assessor ì‹œì‘: {service_name}ì˜ ë¦¬ìŠ¤í¬ í‰ê°€\")\n",
    "    \n",
    "    for category in risk_categories:\n",
    "        print(f\"\\n Â  ğŸ” {category.upper()} ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘...\")\n",
    "        \n",
    "        # 1. Baseline ê·¼ê±° ìš”ì•½ ê²°í•©\n",
    "        baseline_summaries = [\n",
    "            f\"- [Baseline] ì¶œì²˜: {src['source']} {src['chunk_info']}. ìš”ì•½: {src['summary']}\"\n",
    "            for src in evidence_data.get('baseline_sources', []) if src.get('category') == category\n",
    "        ]\n",
    "        \n",
    "        # 2. Issue ê·¼ê±° ìš”ì•½ ê²°í•©\n",
    "        issue_summaries = [\n",
    "            f\"- [Issue] ì¶œì²˜: {src['source']}. ìš”ì•½: {src['summary']}\"\n",
    "            for src in evidence_data.get('issue_sources', []) if src.get('category') == category\n",
    "        ]\n",
    "        \n",
    "        baseline_text = \"\\n\".join(baseline_summaries) if baseline_summaries else \"ì¦ê±° ì—†ìŒ (ë²•ì /ìœ¤ë¦¬ ê¸°ì¤€ ë¯¸í™•ì¸ ë˜ëŠ” ë¬´ê´€)\"\n",
    "        issue_text = \"\\n\".join(issue_summaries) if issue_summaries else \"ì¦ê±° ì—†ìŒ (ìµœì‹  ì‚¬íšŒì  ì´ìŠˆ ë¯¸ë°œê²¬)\"\n",
    "\n",
    "        chain = ASSESSMENT_PROMPT | llm | parser\n",
    "\n",
    "        try:\n",
    "            assessment_result = chain.invoke({\n",
    "                \"schema\": json.dumps(ASSESSOR_OUTPUT_SCHEMA, indent=2, ensure_ascii=False),\n",
    "                \"service_name\": service_name,\n",
    "                \"category\": category,\n",
    "                \"baseline_summaries\": baseline_text,\n",
    "                \"issue_summaries\": issue_text\n",
    "            })\n",
    "            \n",
    "            assessment_result['category'] = category \n",
    "            assessed_risks.append(assessment_result)\n",
    "            print(f\" Â  Â  âœ… í‰ê°€ ì™„ë£Œ: {category.upper()} -> {assessment_result.get('risk_level', 'Unknown')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Â  Â  âŒ í‰ê°€ ì‹¤íŒ¨ ({category}): {e}\")\n",
    "            assessed_risks.append({\n",
    "                \"category\": category,\n",
    "                \"risk_level\": \"Error\",\n",
    "                \"assessment_summary\": f\"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\",\n",
    "                \"recommendation_focus\": \"í‰ê°€ ì‹¤íŒ¨\"\n",
    "            })\n",
    "            \n",
    "    # ìµœì¢… ê²°ê³¼ êµ¬ì¡°í™”\n",
    "    final_assessment = {\n",
    "        \"service_name\": service_name,\n",
    "        \"assessed_risks\": assessed_risks,\n",
    "    }\n",
    "    \n",
    "    # ğŸ’¡ Stateì— í‰ê°€ ê²°ê³¼ ì €ì¥\n",
    "    state['assessment_result'] = final_assessment\n",
    "    state['assessment_status'] = \"Success\"\n",
    "    \n",
    "    print(\"\\nâœ… Risk Assessor í‰ê°€ ë° State ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "    return state # ì—…ë°ì´íŠ¸ëœ State ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3497664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âš–ï¸ Risk Assessor ì‹œì‘ (State ê¸°ë°˜ í…ŒìŠ¤íŠ¸)...\n",
      "============================================================\n",
      "\n",
      "âš–ï¸ Risk Assessor ì‹œì‘: ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ë¦¬ìŠ¤í¬ í‰ê°€\n",
      "\n",
      " Â  ğŸ” BIAS ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘...\n",
      " Â  Â  âœ… í‰ê°€ ì™„ë£Œ: BIAS -> High\n",
      "\n",
      " Â  ğŸ” PRIVACY ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘...\n",
      " Â  Â  âœ… í‰ê°€ ì™„ë£Œ: PRIVACY -> Limited\n",
      "\n",
      " Â  ğŸ” TRANSPARENCY ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘...\n",
      " Â  Â  âœ… í‰ê°€ ì™„ë£Œ: TRANSPARENCY -> Minimal\n",
      "\n",
      "âœ… Risk Assessor í‰ê°€ ë° State ì—…ë°ì´íŠ¸ ì™„ë£Œ!\n",
      "\n",
      "============================================================\n",
      "ğŸ“¢ Risk Assessor ìµœì¢… ê²°ê³¼ (ì—…ë°ì´íŠ¸ëœ State ë‚´ìš©)\n",
      "============================================================\n",
      "{\n",
      "  \"service_name\": \"ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\",\n",
      "  \"assessed_risks\": [\n",
      "    {\n",
      "      \"category\": \"bias\",\n",
      "      \"risk_level\": \"High\",\n",
      "      \"assessment_summary\": \"ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ EU AI Actì— ë”°ë¼ ê³ ìœ„í—˜ìœ¼ë¡œ ë¶„ë¥˜ë˜ë©°, í¸í–¥ì„± ëª¨ë‹ˆí„°ë§ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ìµœê·¼ AI ì±„ìš© ì‹œìŠ¤í…œì˜ ë¶ˆê³µì •ì„± ë¬¸ì œë¡œ ì‚¬íšŒì  ë…¼ë€ì´ ë°œìƒí•˜ê³  ìˆì–´, ê¸°ë³¸ê¶Œ ì¹¨í•´ ìœ„í—˜ì´ í½ë‹ˆë‹¤.\",\n",
      "      \"recommendation_focus\": \"ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´\"\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"privacy\",\n",
      "      \"risk_level\": \"Limited\",\n",
      "      \"assessment_summary\": \"OECDëŠ” ë¯¼ê° ì •ë³´ ì²˜ë¦¬ ì‹œ ìµëª…í™” ê¸°ìˆ  ì ìš©ê³¼ ë°ì´í„° ì£¼ì²´ì˜ í†µì œê¶Œ ê°•í™”ë¥¼ ê¶Œê³ í•˜ê³  ìˆìœ¼ë‚˜, ìµœì‹  ì‚¬íšŒì  ì´ìŠˆëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë¼ì´ë²„ì‹œ ë¦¬ìŠ¤í¬ëŠ” ì œí•œì ì…ë‹ˆë‹¤.\",\n",
      "      \"recommendation_focus\": \"ë°ì´í„° ì£¼ì²´ì˜ í†µì œê¶Œ ê°•í™”\"\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"transparency\",\n",
      "      \"risk_level\": \"Minimal\",\n",
      "      \"assessment_summary\": \"í˜„ì¬ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì— ëŒ€í•œ ë²•ì  ë° ìœ¤ë¦¬ì  ê¸°ì¤€ì´ í™•ì¸ë˜ì§€ ì•Šì•„ íˆ¬ëª…ì„± ë¦¬ìŠ¤í¬ëŠ” ìµœì†Œí•œìœ¼ë¡œ í‰ê°€ë¨. ìµœì‹  ì‚¬íšŒì  ì´ìŠˆ ë˜í•œ ë°œê²¬ë˜ì§€ ì•Šì•„ ì¶”ê°€ì ì¸ ìš°ë ¤ëŠ” ì—†ìŒ. ê·¸ëŸ¬ë‚˜ íˆ¬ëª…ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ë…¸ë ¥ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ.\",\n",
      "      \"recommendation_focus\": \"ì•Œê³ ë¦¬ì¦˜ì˜ ì‘ë™ ë°©ì‹ ë° ê²°ì • ê³¼ì •ì— ëŒ€í•œ ì„¤ëª… ê°•í™”\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "ğŸ”— ë‹¤ìŒ ë‹¨ê³„: Mitigation RecommenderëŠ” state['assessment_result']ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# step5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (State ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âš–ï¸ Risk Assessor ì‹œì‘ (State ê¸°ë°˜ í…ŒìŠ¤íŠ¸)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ğŸ’¡ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„ì‹œ State ê°ì²´ ìƒì„±\n",
    "# ì´ ë°ì´í„°ëŠ” ì‹¤ì œë¡œëŠ” service_profiler.ipynb, evidence_collector.ipynb ì‹¤í–‰ í›„ stateì— ì €ì¥ëœ ìƒíƒœì—¬ì•¼ í•¨.\n",
    "test_state = {\n",
    "    # Service Profilerì˜ ê²°ê³¼ (ì„ íƒ ì‚¬í•­)\n",
    "    \"service_profile\": {\n",
    "        \"service_name\": \"ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\",\n",
    "        \"service_type\": \"recruitment system\", \n",
    "        \"risk_categories\": [\"bias\", \"privacy\", \"transparency\"]\n",
    "    },\n",
    "    # Evidence Collectorì˜ ê²°ê³¼ (í•„ìˆ˜)\n",
    "    \"evidence_data\": {\n",
    "        \"query\": \"ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\",\n",
    "        \"scores\": {\"bias\": 1.0, \"privacy\": 1.0, \"transparency\": 1.0},\n",
    "        \"baseline_sources\": [\n",
    "            {\"category\": \"bias\", \"source\": \"EU_AI_Act.pdf\", \"chunk_info\": \"(í˜ì´ì§€ 10ì˜ ë‚´ìš©)\", \"summary\": \"EU AI ActëŠ” ì±„ìš© AIë¥¼ ê³ ìœ„í—˜ìœ¼ë¡œ ë¶„ë¥˜í•˜ë©°, ê¸°ë³¸ê¶Œ ì¹¨í•´ ìœ„í—˜ì„ ì¤„ì´ê¸° ìœ„í•œ í¸í–¥ì„± ëª¨ë‹ˆí„°ë§ì„ ì˜ë¬´í™”í•œë‹¤.\", \"full_content\": \"...\"},\n",
    "            {\"category\": \"privacy\", \"source\": \"OECD_Privacy_2024.pdf\", \"chunk_info\": \"(í˜ì´ì§€ 5ì˜ ë‚´ìš©)\", \"summary\": \"OECDëŠ” ë¯¼ê° ì •ë³´ ì²˜ë¦¬ ì‹œ ìµëª…í™” ê¸°ìˆ  ì ìš©ê³¼ ë°ì´í„° ì£¼ì²´ì˜ í†µì œê¶Œ ê°•í™”ë¥¼ ê¶Œê³ í•œë‹¤.\", \"full_content\": \"...\"}\n",
    "        ],\n",
    "        \"issue_sources\": [\n",
    "            {\"category\": \"bias\", \"source\": \"AI Ethics Today\", \"url\": \"...\", \"summary\": \"ìµœê·¼ ê¸°ì‚¬ì— ë”°ë¥´ë©´, AI ì±„ìš© ì‹œìŠ¤í…œì´ íŠ¹ì • ì§‘ë‹¨ì—ê²Œ ë¶ˆë¦¬í•˜ê²Œ ì‘ë™í•˜ì—¬ ì‚¬íšŒì  ë…¼ë€ì´ ë˜ê³  ìˆìœ¼ë©° ê³µì •ì„±ì— ëŒ€í•œ ì˜ë¬¸ì´ ì œê¸°ë˜ê³  ìˆë‹¤.\", \"full_content\": \"...\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤í–‰ (State ì—…ë°ì´íŠ¸)\n",
    "updated_state = assess_risk_and_update_state(test_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¢ Risk Assessor ìµœì¢… ê²°ê³¼ (ì—…ë°ì´íŠ¸ëœ State ë‚´ìš©)\")\n",
    "print(\"=\"*60)\n",
    "# ì—…ë°ì´íŠ¸ëœ state['assessment_result'] ë‚´ìš© ì¶œë ¥\n",
    "print(json.dumps(updated_state.get('assessment_result'), indent=2, ensure_ascii=False))\n",
    "\n",
    "print(f\"\\nğŸ”— ë‹¤ìŒ ë‹¨ê³„: Mitigation RecommenderëŠ” state['assessment_result']ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-JIaWGMA_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

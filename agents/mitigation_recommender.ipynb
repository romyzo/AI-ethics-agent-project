{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0002eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 불러오기 완료!\n"
     ]
    }
   ],
   "source": [
    "# step1. 라이브러리 불러오기\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ 라이브러리 불러오기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aeed07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChatOpenAI LLM 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "# step2. LLM 초기화 및 설정\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3) \n",
    "    print(\"✅ ChatOpenAI LLM 초기화 완료!\")\n",
    "except Exception as e:\n",
    "    llm = None\n",
    "    \n",
    "# JSON 출력 구조 정의\n",
    "RECOMMENDATION_OUTPUT_SCHEMA = {\n",
    "    \"recommendation_id\": \"int (1부터 시작)\",\n",
    "    \"recommendation_title\": \"string (개선 항목의 제목)\",\n",
    "    \"mitigation_step\": \"string (실행 가능한 구체적인 개선 조치 설명)\",\n",
    "    \"priority\": \"string (High, Medium, Low 중 하나)\",\n",
    "    \"effort_level\": \"string (Low, Medium, High 중 하나)\",\n",
    "    \"relevant_standard\": \"string (EU AI Act, OECD, UNESCO 중 가장 관련 높은 기준 명시)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9051ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3. 개선 권고 프롬프트 정의\n",
    "RECOMMENDATION_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \n",
    "         \"당신은 AI 윤리 리스크 개선 전문가입니다. \"\n",
    "         \"제공된 리스크 평가 결과와 '개선 권고 초점'을 기반으로, \"\n",
    "         \"구체적이고 실행 가능한 개선 권고안을 3가지 이상 생성하여 JSON 배열 형식으로만 반환하세요. \"\n",
    "         \"반드시 출력 JSON 스키마를 준수해야 합니다.\"\n",
    "         \"\\n\\n[출력 JSON 스키마]:\\n{schema}\"\n",
    "        ),\n",
    "        (\"human\", \n",
    "         \"--- 서비스 및 리스크 평가 정보 ---\"\n",
    "         \"\\n서비스명: {service_name}\"\n",
    "         \"\\n평가 리스크 카테고리: {category}\"\n",
    "         \"\\n위험도 수준: {risk_level}\"\n",
    "         \"\\n평가 요약: {assessment_summary}\"\n",
    "         \"\\n--- 개선 권고 초점 ---\"\n",
    "         \"\\n{recommendation_focus}\"\n",
    "         \"\\n\\n위 정보를 바탕으로 **{recommendation_focus}**를 해결할 수 있는 구체적인 개선 권고안을 생성하세요. \"\n",
    "         \"우선순위(Priority)는 리스크 수준과 연관시켜 설정하세요.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e880d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4. 권고안 생성 함수 정의 (State를 입력으로 받도록 변경)\n",
    "def generate_recommendations_and_update_state(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    State에서 평가 결과를 읽고, 개선 권고안을 생성한 후, State에 결과를 저장합니다.\n",
    "    \"\"\"\n",
    "    if not llm:\n",
    "        state['recommendation_status'] = \"Error: LLM failed to initialize.\"\n",
    "        return state\n",
    "    \n",
    "    assessment_data = state.get('assessment_result', {})\n",
    "    if not assessment_data or not assessment_data.get('assessed_risks'):\n",
    "        state['recommendation_status'] = \"Error: Missing assessment_result in state.\"\n",
    "        return state\n",
    "    \n",
    "    service_name = assessment_data.get('service_name', 'AI 서비스')\n",
    "    risks_to_mitigate = [\n",
    "        r for r in assessment_data['assessed_risks'] \n",
    "        if r['risk_level'] in ['High', 'Limited'] # High와 Limited 리스크만 권고안 생성\n",
    "    ]\n",
    "    \n",
    "    all_recommendations = []\n",
    "    parser = JsonOutputParser(pydantic_object=None)\n",
    "    \n",
    "    print(f\"\\n💡 Mitigation Recommender 시작: {service_name}의 개선 권고안 생성\")\n",
    "    \n",
    "    for risk in risks_to_mitigate:\n",
    "        category = risk['category']\n",
    "        print(f\"\\n   ⚙️ {category.upper()} 리스크 개선 권고안 생성 중...\")\n",
    "        \n",
    "        chain = RECOMMENDATION_PROMPT | llm | parser\n",
    "\n",
    "        try:\n",
    "            recommendation_list = chain.invoke({\n",
    "                \"schema\": json.dumps(RECOMMENDATION_OUTPUT_SCHEMA, indent=2, ensure_ascii=False),\n",
    "                \"service_name\": service_name,\n",
    "                \"category\": category,\n",
    "                \"risk_level\": risk['risk_level'],\n",
    "                \"assessment_summary\": risk['assessment_summary'],\n",
    "                \"recommendation_focus\": risk['recommendation_focus']\n",
    "            })\n",
    "            \n",
    "            # 카테고리 정보와 함께 리스트에 추가\n",
    "            for rec in recommendation_list:\n",
    "                rec['risk_category'] = category\n",
    "            \n",
    "            all_recommendations.extend(recommendation_list)\n",
    "            print(f\"     ✅ 권고안 {len(recommendation_list)}개 생성 완료: {category.upper()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"     ❌ 권고안 생성 실패 ({category}): {e}\")\n",
    "            \n",
    "    # 💡 State에 권고안 결과 저장\n",
    "    state['recommendation_result'] = all_recommendations\n",
    "    state['recommendation_status'] = \"Success\"\n",
    "    \n",
    "    print(\"\\n✅ Mitigation Recommender 완료 및 State 업데이트 완료!\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91047507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "💡 Mitigation Recommender 시작 (State 기반 테스트)...\n",
      "============================================================\n",
      "\n",
      "💡 Mitigation Recommender 시작: 이력서 분석 추천 시스템의 개선 권고안 생성\n",
      "\n",
      "   ⚙️ BIAS 리스크 개선 권고안 생성 중...\n",
      "     ✅ 권고안 3개 생성 완료: BIAS\n",
      "\n",
      "   ⚙️ PRIVACY 리스크 개선 권고안 생성 중...\n",
      "     ✅ 권고안 3개 생성 완료: PRIVACY\n",
      "\n",
      "✅ Mitigation Recommender 완료 및 State 업데이트 완료!\n",
      "\n",
      "============================================================\n",
      "📢 Mitigation Recommender 최종 결과 (업데이트된 State 내용)\n",
      "============================================================\n",
      "총 생성된 권고안 개수: 6개\n",
      "[\n",
      "  {\n",
      "    \"recommendation_id\": 1,\n",
      "    \"recommendation_title\": \"데이터 수집 프로세스 개선\",\n",
      "    \"mitigation_step\": \"다양한 인구 통계학적 배경을 반영한 데이터 수집을 위해, 채용 시장의 다양한 집단을 포함하는 샘플링 전략을 수립하고, 특정 성별 및 출신 배경에 대한 편향을 최소화하기 위한 가이드라인을 마련한다.\",\n",
      "    \"priority\": \"High\",\n",
      "    \"effort_level\": \"Medium\",\n",
      "    \"relevant_standard\": \"EU AI Act\",\n",
      "    \"risk_category\": \"bias\"\n",
      "  },\n",
      "  {\n",
      "    \"recommendation_id\": 2,\n",
      "    \"recommendation_title\": \"모델 공정성 감사 프로세스 구축\",\n",
      "    \"mitigation_step\": \"AI 모델의 공정성을 평가하기 위한 독립적인 감사 팀을 구성하고, 정기적으로 모델의 성능을 분석하여 성별 및 출신에 따른 편향성을 점검하는 프로세스를 수립한다.\",\n",
      "    \"priority\": \"High\",\n",
      "    \"effort_level\": \"High\",\n",
      "    \"relevant_standard\": \"OECD\",\n",
      "    \"risk_category\": \"bias\"\n",
      "  },\n",
      "  {\n",
      "    \"recommendation_id\": 3,\n",
      "    \"recommendation_title\": \"편향성 모니터링 시스템 도입\",\n",
      "    \"mitigation_step\": \"AI 모델의 예측 결과에 대한 지속적인 모니터링 시스템을 구축하여, 특정 집단에 대한 차별적 결과가 발생할 경우 즉각적으로 조치를 취할 수 있도록 한다.\",\n",
      "    \"priority\": \"High\",\n",
      "    \"effort_level\": \"Medium\",\n",
      "    \"relevant_standard\": \"UNESCO\",\n",
      "    \"risk_category\": \"bias\"\n",
      "  },\n",
      "  {\n",
      "    \"recommendation_id\": 1,\n",
      "    \"recommendation_title\": \"익명화 기술 강화\",\n",
      "    \"mitigation_step\": \"최신 익명화 기술 및 알고리즘을 도입하여 개인 식별 정보를 더욱 효과적으로 제거하고, 데이터 분석 후에도 개인이 식별되지 않도록 보장합니다.\",\n",
      "    \"priority\": \"High\",\n",
      "    \"effort_level\": \"Medium\",\n",
      "    \"relevant_standard\": \"EU AI Act\",\n",
      "    \"risk_category\": \"privacy\"\n",
      "  },\n",
      "  {\n",
      "    \"recommendation_id\": 2,\n",
      "    \"recommendation_title\": \"데이터 주체 동의 절차 개선\",\n",
      "    \"mitigation_step\": \"사용자가 데이터 수집 및 처리에 대한 명확한 동의를 할 수 있도록, 간단하고 이해하기 쉬운 동의 양식을 설계하고, 동의 철회 절차를 명확히 안내합니다.\",\n",
      "    \"priority\": \"High\",\n",
      "    \"effort_level\": \"Low\",\n",
      "    \"relevant_standard\": \"OECD\",\n",
      "    \"risk_category\": \"privacy\"\n",
      "  },\n",
      "  {\n",
      "    \"recommendation_id\": 3,\n",
      "    \"recommendation_title\": \"정기적인 익명화 검토 및 감사\",\n",
      "    \"mitigation_step\": \"익명화 프로세스의 효과성을 정기적으로 검토하고, 외부 전문가에 의한 감사를 통해 지속적으로 개선 사항을 도출합니다.\",\n",
      "    \"priority\": \"Medium\",\n",
      "    \"effort_level\": \"High\",\n",
      "    \"relevant_standard\": \"UNESCO\",\n",
      "    \"risk_category\": \"privacy\"\n",
      "  }\n",
      "]\n",
      "\n",
      "🔗 다음 단계: Report Composer는 state['assessment_result']와 state['recommendation_result']를 입력으로 사용합니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# step5. 테스트 실행 (Risk Assessor의 결과 더미 데이터 사용)\n",
    "# 이 데이터는 실제로는 state['assessment_result']에 저장되어 있어야 함.\n",
    "\n",
    "test_state = {\n",
    "    'assessment_result': {\n",
    "        \"service_name\": \"이력서 분석 추천 시스템\",\n",
    "        \"assessed_risks\": [\n",
    "            {\n",
    "                \"category\": \"bias\",\n",
    "                \"risk_level\": \"High\",\n",
    "                \"assessment_summary\": \"채용 AI는 고위험으로 분류되며, 최신 사회 이슈에서 성별/출신 편향성 문제가 명확히 드러남. 즉각적인 조치가 필요함.\",\n",
    "                \"recommendation_focus\": \"데이터 다양성 확보 및 모델 공정성 감사 프로세스 구축\"\n",
    "            },\n",
    "            {\n",
    "                \"category\": \"privacy\",\n",
    "                \"risk_level\": \"Limited\",\n",
    "                \"assessment_summary\": \"민감 정보를 처리하나, 익명화 기술 적용이 가능하여 위험도는 중간 수준임. 데이터 통제권 강화가 필요함.\",\n",
    "                \"recommendation_focus\": \"익명화 수준 강화 및 데이터 주체 동의 명확화\"\n",
    "            },\n",
    "            {\n",
    "                \"category\": \"transparency\",\n",
    "                \"risk_level\": \"Minimal\",\n",
    "                \"assessment_summary\": \"알고리즘의 결정 과정 공개 의무는 있으나, 현재까지 큰 사회적 이슈는 없음. 설명 가능성 문서화 수준으로 충분함.\",\n",
    "                \"recommendation_focus\": \"결정 근거 문서화 및 이해관계자에게 설명 가능한 인터페이스 제공\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"💡 Mitigation Recommender 시작 (State 기반 테스트)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "updated_state = generate_recommendations_and_update_state(test_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📢 Mitigation Recommender 최종 결과 (업데이트된 State 내용)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"총 생성된 권고안 개수: {len(updated_state.get('recommendation_result', []))}개\")\n",
    "print(json.dumps(updated_state.get('recommendation_result'), indent=2, ensure_ascii=False))\n",
    "\n",
    "print(f\"\\n🔗 다음 단계: Report Composer는 state['assessment_result']와 state['recommendation_result']를 입력으로 사용합니다.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-JIaWGMA_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

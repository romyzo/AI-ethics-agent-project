{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe3d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "\n",
    "# 👩‍💻 Author    : Hyelim Jo\n",
    "# 🎯 Purpose   : AI 윤리성 리스크 진단 에이전트 v1.0\n",
    "# 📅 Created   : 2025-10-22\n",
    "# 📜 Note      : evidence_collector.ipynb\n",
    "\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d45862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- Update Log ----------------------------------\n",
    "\n",
    "# 2025-10-22 16:00 / 초기 생성 / Evidence Collector 기본 구조 구현\n",
    "# 2025-10-22 16:30 / RAG 메모리 설계 / Baseline + Issue 메모리 분리\n",
    "# 2025-10-22 17:00 / HuggingFace 임베딩 적용 / 경제성 개선\n",
    "# 2025-10-23 09:00 / 웹 크롤링 실제 구현 / Tavily Search API를 사용하여 최신 뉴스/논문 수집\n",
    "# 2025-10-23 09:30 / Baseline 쿼리 강화 / EU, OECD, UNESCO 기준 명시 및 파일 구성에 맞춰 로드 로직 명확화\n",
    "\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ef9c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 불러오기 완료!\n"
     ]
    }
   ],
   "source": [
    "# step1. 라이브러리 불러오기\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI # LLM 사용을 위해 필요\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 라이브러리 불러오기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22844965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 경로 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# step2. 설정 및 경로 정의\n",
    "# 데이터 경로 설정 (agents 폴더 내에서 실행 가정)\n",
    "base_dir = os.path.join(\"..\", \"data\")\n",
    "reference_dir = os.path.join(base_dir, \"reference\")\n",
    "crawled_dir = os.path.join(base_dir, \"crawled\")\n",
    "processed_dir = os.path.join(base_dir, \"processed\")\n",
    "baseline_embed_dir = os.path.join(base_dir, \"embeddings\", \"baseline\")\n",
    "issue_embed_dir = os.path.join(base_dir, \"embeddings\", \"issue\")\n",
    "\n",
    "# 디렉토리 생성\n",
    "for dir_path in [crawled_dir, processed_dir, baseline_embed_dir, issue_embed_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"✅ 경로 설정 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decd4add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKAX\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-JIaWGMA_-py3.11\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChatOpenAI LLM 초기화 완료!\n",
      "✅ HuggingFace 임베딩 모델 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "# step3. 임베딩 모델 및 LLM 초기화\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "# 💡 LLM 초기화 (요약 및 평가에 사용)\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    print(\"✅ ChatOpenAI LLM 초기화 완료!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ ChatOpenAI 초기화 실패: {e}\")\n",
    "    llm = None\n",
    "\n",
    "print(\"✅ HuggingFace 임베딩 모델 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad70088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline 메모리 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step4. Baseline 메모리 구축 (EU, OECD, UNESCO 문서)\n",
    "def build_baseline_memory():\n",
    "    \"\"\"공식 문서 기반 Baseline 메모리 구축\"\"\"\n",
    "    baseline_docs = []\n",
    "    \n",
    "    # PDF 파일 로드\n",
    "    pdf_files = [\n",
    "        \"EU_AI_Act.pdf\",\n",
    "        \"OECD_Privacy_2024.pdf\", \n",
    "        \"UNESCO_Ethics_2021.pdf\"\n",
    "    ]\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(reference_dir, pdf_file)\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            loader = PyMuPDFLoader(pdf_path)\n",
    "            docs = loader.load()\n",
    "            print(f\"✅ {pdf_file} 로드 완료\")\n",
    "            \n",
    "            # 메타데이터에 문서 타입 추가 및 페이지 번호 정보 포함\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"document_type\"] = \"baseline\"\n",
    "                doc.metadata[\"source\"] = pdf_file\n",
    "                doc.metadata[\"page\"] = doc.metadata.get(\"page\", 0) + 1 # 페이지 번호는 1부터 시작\n",
    "            baseline_docs.extend(docs)\n",
    "        else:\n",
    "            print(f\"⚠️ {pdf_file} 파일이 지정된 경로에 없습니다: {pdf_path}\")\n",
    "    \n",
    "    if not baseline_docs:\n",
    "        print(\"❌ Baseline 문서를 로드하지 못했습니다. RAG가 Baseline 증거를 찾지 못할 수 있습니다.\")\n",
    "        split_docs = [Document(page_content=\"No official baseline documents loaded.\", metadata={\"source\": \"N/A\", \"document_type\": \"baseline\", \"page\": 0})]\n",
    "    else:\n",
    "        # 텍스트 분할\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        split_docs = text_splitter.split_documents(baseline_docs)\n",
    "    \n",
    "    # ChromaDB에 저장\n",
    "    baseline_vectorstore = Chroma.from_documents(\n",
    "        documents=split_docs,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=baseline_embed_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Baseline 메모리 구축 완료 ({len(split_docs)}개 청크)\")\n",
    "    return baseline_vectorstore\n",
    "\n",
    "print(\"✅ Baseline 메모리 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c485a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 웹 크롤링 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step5. 웹 크롤링 함수 정의 (Tavily 사용)\n",
    "def crawl_web_content(keywords: List[str]) -> List[Dict[str, Any]]:\n",
    "    # ... (Tavily search logic remains the same)\n",
    "    tavily = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))\n",
    "    crawled_data = []\n",
    "    search_queries = []\n",
    "    for keyword in keywords:\n",
    "        search_queries.extend([\n",
    "            f\"AI {keyword} 윤리 이슈\",\n",
    "            f\"AI {keyword} 편향성 문제\",\n",
    "            f\"AI {keyword} 개인정보보호\",\n",
    "        ])\n",
    "    unique_queries = list(set(search_queries))[:5]\n",
    "    \n",
    "    for query in unique_queries:\n",
    "        print(f\"    - Tavily 검색 중: {query}...\")\n",
    "        try:\n",
    "            results = tavily.search(\n",
    "                query=query, \n",
    "                search_depth=\"advanced\", \n",
    "                max_results=5, \n",
    "                include_raw_content=True\n",
    "            )\n",
    "            for result in results.get(\"results\", []):\n",
    "                if result.get(\"content\"):\n",
    "                    crawled_data.append({\n",
    "                        \"title\": result.get(\"title\", \"No Title\"),\n",
    "                        \"content\": result[\"content\"],\n",
    "                        \"source\": result.get(\"url\", \"Unknown Source\"),\n",
    "                        \"url\": result.get(\"url\", \"\"),\n",
    "                        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                        \"category\": \"issue\"\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Tavily 검색 실패 ({query}): {e}\")\n",
    "            continue\n",
    "\n",
    "    # 필터링 로직 (300자 이상, 선정적 표현 제거, 중복 URL 제거)\n",
    "    filtered_data = []\n",
    "    for item in crawled_data:\n",
    "        if len(item[\"content\"]) >= 300:\n",
    "            if not any(word in item[\"content\"].lower() for word in [\"충격\", \"폭로\", \"clickbait\", \"논란의\", \"대박\"]):\n",
    "                if item[\"url\"] not in [d.get(\"url\") for d in filtered_data]:\n",
    "                    filtered_data.append(item)\n",
    "\n",
    "    print(f\"✅ 웹 크롤링 완료 ({len(filtered_data)}개 문서)\")\n",
    "    return filtered_data\n",
    "\n",
    "print(\"✅ 웹 크롤링 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e403121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Issue 메모리 구축 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step6. Issue 메모리 구축 (웹 크롤링 결과를 RAG에 저장)\n",
    "def build_issue_memory(keywords: List[str]):\n",
    "    # ... (Issue memory build logic remains the same)\n",
    "    crawled_data = crawl_web_content(keywords)\n",
    "    issue_docs = []\n",
    "    \n",
    "    for item in crawled_data:\n",
    "        doc = Document(\n",
    "            page_content=f\"[이슈: {item['category']}] {item['title']}\\n\\n{item['content']}\",\n",
    "            metadata={\n",
    "                \"document_type\": \"issue\",\n",
    "                \"source\": item[\"source\"],\n",
    "                \"url\": item[\"url\"],\n",
    "                \"date\": item[\"date\"],\n",
    "                \"category\": item[\"category\"],\n",
    "                \"title\": item[\"title\"]\n",
    "            }\n",
    "        )\n",
    "        issue_docs.append(doc)\n",
    "    \n",
    "    if issue_docs:\n",
    "        issue_vectorstore = Chroma.from_documents(\n",
    "            documents=issue_docs,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=issue_embed_dir\n",
    "        )\n",
    "        print(f\"✅ Issue 메모리 구축 완료 ({len(issue_docs)}개 문서)\")\n",
    "        return issue_vectorstore\n",
    "    else:\n",
    "        print(\"⚠️ 크롤링된 데이터가 없습니다.\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Issue 메모리 구축 함수 정의 완료\")\n",
    "\n",
    "\n",
    "# 💡 신규 함수 정의: LLM을 이용한 증거 요약\n",
    "def summarize_evidence_with_llm(docs: List[Document], query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"검색된 Document 목록을 LLM을 사용하여 요약하고 세부 정보와 결합합니다.\"\"\"\n",
    "    if not llm:\n",
    "        print(\"⚠️ LLM이 초기화되지 않아 요약을 건너뜁니다.\")\n",
    "        return []\n",
    "\n",
    "    summarized_results = []\n",
    "    \n",
    "    summary_prompt_template = \"\"\"당신은 AI 윤리 리스크 진단 전문가입니다. 다음 정보를 분석하여 한국어로 3줄 이내의 간결하고 핵심적인 요약을 제공하세요.\n",
    "    이 요약은 'AI 서비스 {query}의 윤리 리스크'에 대한 근거로 사용될 것입니다.\n",
    "    ---\n",
    "    문서 출처: {source} ({document_type}) {chunk_info}\n",
    "    문서 내용: {content}\n",
    "    ---\n",
    "    요약:\"\"\"\n",
    "    summary_prompt = PromptTemplate(template=summary_prompt_template, input_variables=[\"query\", \"source\", \"document_type\", \"content\", \"chunk_info\"])\n",
    "\n",
    "    for doc in docs:\n",
    "        content = doc.page_content\n",
    "        source = doc.metadata.get(\"source\", doc.metadata.get(\"url\", \"Unknown\"))\n",
    "        doc_type = doc.metadata.get(\"document_type\", \"Unknown\")\n",
    "        category = doc.metadata.get(\"category\", \"N/A\")\n",
    "\n",
    "        # 문서 타입에 따른 청크 정보 설정\n",
    "        if doc_type == \"baseline\":\n",
    "            chunk_info = f\"(페이지 {doc.metadata.get('page', 'N/A')}의 내용)\"\n",
    "            score = 0.8\n",
    "        else: # issue\n",
    "            chunk_info = \"(웹 기사 원문)\"\n",
    "            score = 0.2\n",
    "\n",
    "        # 프롬프트 구성 및 요약 생성\n",
    "        prompt_value = summary_prompt.invoke({\n",
    "            \"query\": query,\n",
    "            \"source\": source,\n",
    "            \"document_type\": doc_type,\n",
    "            \"content\": content,\n",
    "            \"chunk_info\": chunk_info\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # LLM 호출\n",
    "            summary_response = llm.invoke(prompt_value.to_string())\n",
    "            summary = summary_response.content.strip()\n",
    "        except Exception as e:\n",
    "            summary = f\"LLM 요약 실패. Error: {e}\"\n",
    "        \n",
    "        # Risk Assessor 에이전트에 전달할 상세 구조\n",
    "        summarized_results.append({\n",
    "            \"category\": category,\n",
    "            \"document_type\": doc_type,\n",
    "            \"source\": source,\n",
    "            \"chunk_info\": chunk_info, # PDF 페이지 또는 웹 기사 여부\n",
    "            \"score\": score,\n",
    "            \"summary\": summary, \n",
    "            \"content_excerpt\": content[:300] + \"...\", # 원문 내용의 일부 (너무 길어지지 않도록)\n",
    "            \"full_content\": content # Risk Assessor에서 필요할 경우를 대비하여 전체 원문도 전달\n",
    "        })\n",
    "        \n",
    "    return summarized_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a131f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 증거 수집 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step7. 증거 수집 함수 정의 (가중치 8:2 적용)\n",
    "def collect_evidence(service_profile: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    서비스 프로파일 기반 증거 수집 (Baseline 0.8 : Issue 0.2)\n",
    "    - Risk Assessor에게 전달할 증거 소스 목록 및 가중치 점수, 요약 포함\n",
    "    \"\"\"\n",
    "    \n",
    "    service_name = service_profile.get(\"service_name\", \"\")\n",
    "    risk_categories = service_profile.get(\"risk_categories\", [])\n",
    "    service_type = service_profile.get(\"service_type\", \"\")\n",
    "    \n",
    "    print(f\"\\n🔍 증거 수집 시작: {service_name}\")\n",
    "    \n",
    "    # 메모리 구축\n",
    "    baseline_vectorstore = build_baseline_memory()\n",
    "    issue_vectorstore = build_issue_memory(risk_categories)\n",
    "    \n",
    "    evidence_results = {\n",
    "        \"query\": service_name,\n",
    "        \"weights\": {\"baseline\": 0.8, \"issue\": 0.2},\n",
    "        \"scores\": {},\n",
    "        \"baseline_sources\": [],\n",
    "        \"issue_sources\": []\n",
    "    }\n",
    "    \n",
    "    all_docs_to_summarize = []\n",
    "    \n",
    "    # 1. 각 리스크 카테고리별 증거 검색\n",
    "    for category in risk_categories:\n",
    "        \n",
    "        # Baseline 검색 쿼리 강화\n",
    "        baseline_query = f\"{service_name} {category} 리스크 {service_type} (EU AI Act, OECD, UNESCO 윤리 기준)\"\n",
    "        issue_query = f\"최신 뉴스 논문 AI {service_name} {category} 문제\"\n",
    "        \n",
    "        print(f\"\\n   📊 {category.upper()} 리스크 검색 중...\")\n",
    "        \n",
    "        # Baseline 검색\n",
    "        baseline_docs = baseline_vectorstore.similarity_search(baseline_query, k=3)\n",
    "        \n",
    "        # Issue 검색\n",
    "        issue_docs = []\n",
    "        if issue_vectorstore:\n",
    "            issue_docs = issue_vectorstore.similarity_search(issue_query, k=2)\n",
    "            \n",
    "        # 검색된 문서를 요약 대상 리스트에 추가 (카테고리 메타데이터 부여)\n",
    "        for doc in baseline_docs:\n",
    "            doc.metadata['category'] = category\n",
    "            all_docs_to_summarize.append(doc)\n",
    "        for doc in issue_docs:\n",
    "            doc.metadata['category'] = category\n",
    "            all_docs_to_summarize.append(doc)\n",
    "            \n",
    "        # 종합 점수 계산 (참고용)\n",
    "        baseline_weight = 0.8\n",
    "        issue_weight = 0.2 if issue_docs else 0.0\n",
    "        total_score = (len(baseline_docs) > 0) * baseline_weight + (len(issue_docs) > 0) * issue_weight\n",
    "        evidence_results[\"scores\"][category] = total_score\n",
    "        \n",
    "        print(f\" - 검색된 Baseline 청크: {len(baseline_docs)}개\")\n",
    "        print(f\" - 검색된 Issue 문서: {len(issue_docs)}개\")\n",
    "\n",
    "    print(\"\\n📝 검색된 증거들을 LLM을 사용하여 요약 중...\")\n",
    "    \n",
    "    # 2. 통합 요약 및 데이터 구조화\n",
    "    summarized_evidences = summarize_evidence_with_llm(all_docs_to_summarize, service_name)\n",
    "    \n",
    "    # 3. 최종 결과 리스트에 추가\n",
    "    for evidence in summarized_evidences:\n",
    "        if evidence['document_type'] == 'baseline':\n",
    "            evidence_results[\"baseline_sources\"].append(evidence)\n",
    "        elif evidence['document_type'] == 'issue':\n",
    "            evidence_results[\"issue_sources\"].append(evidence)\n",
    "    \n",
    "    print(f\"\\n✅ 증거 수집 및 요약 완료!\")\n",
    "    return evidence_results\n",
    "\n",
    "print(\"✅ 증거 수집 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a4c0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔍 Evidence Collector 시작...\n",
      "============================================================\n",
      "\n",
      "📝 분석할 서비스: 채용 지원자의 이력서를 AI로 분석하여 적합한 후보자를 추천하는 시스템입니다....\n",
      "\n",
      "🔍 증거 수집 시작: 이력서 분석 추천 시스템\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EU_AI_Act.pdf 로드 완료\n",
      "✅ OECD_Privacy_2024.pdf 로드 완료\n",
      "✅ UNESCO_Ethics_2021.pdf 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline 메모리 구축 완료 (2075개 청크)\n",
      "    - Tavily 검색 중: AI bias 편향성 문제...\n",
      "    - Tavily 검색 중: AI privacy 편향성 문제...\n",
      "    - Tavily 검색 중: AI transparency 개인정보보호...\n",
      "    - Tavily 검색 중: AI privacy 윤리 이슈...\n",
      "    - Tavily 검색 중: AI bias 윤리 이슈...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 웹 크롤링 완료 (23개 문서)\n",
      "✅ Issue 메모리 구축 완료 (23개 문서)\n",
      "\n",
      "   📊 BIAS 리스크 검색 중...\n",
      " - 검색된 Baseline 청크: 3개\n",
      " - 검색된 Issue 문서: 2개\n",
      "\n",
      "   📊 PRIVACY 리스크 검색 중...\n",
      " - 검색된 Baseline 청크: 3개\n",
      " - 검색된 Issue 문서: 2개\n",
      "\n",
      "   📊 TRANSPARENCY 리스크 검색 중...\n",
      " - 검색된 Baseline 청크: 3개\n",
      " - 검색된 Issue 문서: 2개\n",
      "\n",
      "📝 검색된 증거들을 LLM을 사용하여 요약 중...\n",
      "\n",
      "✅ 증거 수집 및 요약 완료!\n",
      "\n",
      "============================================================\n",
      "📊 증거 수집 결과 요약 및 다음 에이전트 전달 내용\n",
      "============================================================\n",
      "  - 서비스명: 이력서 분석 추천 시스템\n",
      "  - 가중치: Baseline 0.8 : Issue 0.2\n",
      "  - 수집된 리스크 카테고리: ['bias', 'privacy', 'transparency']\n",
      "\n",
      "------------------------------------------------------------\n",
      "🚨 Risk Assessor에 전달되는 데이터 구조 요약 (첫 번째 증거 예시)\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Baseline 근거 예시]\n",
      "  - 리스크 카테고리: BIAS\n",
      "  - 출처: UNESCO_Ethics_2021.pdf (페이지 40의 내용)\n",
      "  - **요약 (핵심 근거):** AI 서비스 이력서 분석 추천 시스템은 UNESCO의 정책 권고사항에 따라 윤리적 기준을 준수해야 하며, 이를 위해 경험 공유 메커니즘과 AI 규제 샌드박스가 필요하다. 이러한 도구들은 AI 관련 주체들이 윤리 리스크를 평가하고 개선할 수 있도록 지원한다. 따라서 시스템의 설계와 운영에서 윤리적 고려가 필수적이다.\n",
      "  - 원문 내용 (일부): across UNESCO’s areas of competence, an experience-\n",
      "sharing mechanism, AI regulatory sandboxes, and an \n",
      "assessment guide for all AI actors to evaluate their \n",
      "adherence to policy recommendations mentioned in \n",
      "this document....\n",
      "\n",
      "[Issue 근거 예시]\n",
      "  - 리스크 카테고리: BIAS\n",
      "  - 출처: https://dailyan.com/news/article.html?no=731402 (N/A) (웹 기사 원문)\n",
      "  - **요약 (사회적 반응):** AI 서비스 이력서 분석 추천 시스템은 편향된 학습 데이터로 인해 차별적 결과를 초래할 위험이 있으며, 이는 사회적 불평등을 심화시킬 수 있다. 또한, AI의 결정에 대한 책임 소재가 불명확하여 법적 및 윤리적 혼란을 야기할 수 있다. 따라서 윤리적 고려와 투명성을 강화하고, 명확한 기준을 마련하는 것이 필수적이다.\n",
      "  - 원문 내용 (일부): [이슈: issue] AI 개발의 윤리적 문제점 심화: 책임 소재와 편향성 논란 확대\n",
      "\n",
      "페이스북\n",
      " 엑스\n",
      " 카카오톡\n",
      " 네이버블로그\n",
      "\n",
      "### 급속한 AI 발전 속에서 윤리적 문제가 사회적 논쟁으로 확대되는 현황 분석\n",
      "\n",
      "데일리연합 (SNSJTV. 타임즈M) 김민제 기자 | 최근 급속도로 발전하는 인공지능(AI) 기술은 편리함과 효율성을 제공하지만 동시에 심각한 윤리적 문제를 야기한다는 우려가 커지고 있다.\n",
      "\n",
      "AI 개발 과정에서 발생하는 편향성 문제는 심각한 사회적 불평등을 초래할 수 있다. AI 알고리즘은 학습 데이터에 의존하는데, 이 ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "🔗 최종적으로 15개의 상세 증거가 Risk Assessor로 전달됩니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# step8. 테스트 실행\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔍 Evidence Collector 시작...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Service Profiler에서 받은 결과 (예시)\n",
    "test_service_profile = {\n",
    "    \"service_name\": \"이력서 분석 추천 시스템\",\n",
    "    \"service_type\": \"recruitment system\", \n",
    "    \"description\": \"채용 지원자의 이력서를 AI로 분석하여 적합한 후보자를 추천하는 시스템입니다.\",\n",
    "    \"risk_categories\": [\"bias\", \"privacy\", \"transparency\"]\n",
    "}\n",
    "\n",
    "print(f\"\\n📝 분석할 서비스: {test_service_profile['description']}...\")\n",
    "\n",
    "# 증거 수집 실행\n",
    "evidence_result = collect_evidence(test_service_profile)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 증거 수집 결과 요약 및 다음 에이전트 전달 내용\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  - 서비스명: {evidence_result['query']}\")\n",
    "print(f\"  - 가중치: Baseline {evidence_result['weights']['baseline']} : Issue {evidence_result['weights']['issue']}\")\n",
    "print(f\"  - 수집된 리스크 카테고리: {list(evidence_result['scores'].keys())}\")\n",
    "\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(\"🚨 Risk Assessor에 전달되는 데이터 구조 요약 (첫 번째 증거 예시)\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# 전달될 데이터 구조 예시 출력 (첫 번째 Baseline 소스와 첫 번째 Issue 소스)\n",
    "if evidence_result['baseline_sources']:\n",
    "    b_src = evidence_result['baseline_sources'][0]\n",
    "    print(\"\\n[Baseline 근거 예시]\")\n",
    "    print(f\"  - 리스크 카테고리: {b_src['category'].upper()}\")\n",
    "    print(f\"  - 출처: {b_src['source']} {b_src['chunk_info']}\")\n",
    "    print(f\"  - **요약 (핵심 근거):** {b_src['summary']}\")\n",
    "    print(f\"  - 원문 내용 (일부): {b_src['content_excerpt']}\")\n",
    "\n",
    "if evidence_result['issue_sources']:\n",
    "    i_src = evidence_result['issue_sources'][0]\n",
    "    print(\"\\n[Issue 근거 예시]\")\n",
    "    print(f\"  - 리스크 카테고리: {i_src['category'].upper()}\")\n",
    "    print(f\"  - 출처: {i_src['source']} ({i_src.get('url', 'N/A')}) {i_src['chunk_info']}\")\n",
    "    print(f\"  - **요약 (사회적 반응):** {i_src['summary']}\")\n",
    "    print(f\"  - 원문 내용 (일부): {i_src['content_excerpt']}\")\n",
    "\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(f\"🔗 최종적으로 {len(evidence_result['baseline_sources']) + len(evidence_result['issue_sources'])}개의 상세 증거가 Risk Assessor로 전달됩니다.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-JIaWGMA_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

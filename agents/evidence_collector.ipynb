{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fe3d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "\n",
    "# ğŸ‘©â€ğŸ’» Author Â  Â : Hyelim Jo\n",
    "# ğŸ¯ Purpose Â  : AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ v1.0\n",
    "# ğŸ“… Created Â  : 2025-10-22\n",
    "# ğŸ“œ Note Â  Â  Â : evidence_collector.ipynb\n",
    "\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17d45862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- Update Log ----------------------------------\n",
    "\n",
    "# 2025-10-22 16:00 / ì´ˆê¸° ìƒì„± / Evidence Collector ê¸°ë³¸ êµ¬ì¡° êµ¬í˜„\n",
    "# 2025-10-22 16:30 / RAG ë©”ëª¨ë¦¬ ì„¤ê³„ / Baseline + Issue ë©”ëª¨ë¦¬ ë¶„ë¦¬\n",
    "# 2025-10-22 17:00 / HuggingFace ì„ë² ë”© ì ìš© / ê²½ì œì„± ê°œì„ \n",
    "# 2025-10-23 09:00 / ì›¹ í¬ë¡¤ë§ ì‹¤ì œ êµ¬í˜„ / Tavily Search APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤/ë…¼ë¬¸ ìˆ˜ì§‘\n",
    "# 2025-10-23 09:30 / Baseline ì¿¼ë¦¬ ê°•í™” / EU, OECD, UNESCO ê¸°ì¤€ ëª…ì‹œ ë° íŒŒì¼ êµ¬ì„±ì— ë§ì¶° ë¡œë“œ ë¡œì§ ëª…í™•í™”\n",
    "# 2025-10-23 11:00 / í‰ê°€ ë¡œì§ êµ¬í˜„ / LLM ê¸°ë°˜ì˜ ìœ„í—˜ë„(High/Limited/Minimal) í‰ê°€\n",
    "# 2025-10-23 11:30 / JSON ì¶œë ¥ í¬ë§· ì •ì˜ / Mitigation Recommenderì—ê²Œ ì „ë‹¬í•  êµ¬ì¡° í™•ì •\n",
    "\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23ef9c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# step1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI # LLM ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22844965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2. ì„¤ì • ë° ê²½ë¡œ ì •ì˜\n",
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì • (agents í´ë” ë‚´ì—ì„œ ì‹¤í–‰ ê°€ì •)\n",
    "base_dir = os.path.join(\"..\", \"data\")\n",
    "reference_dir = os.path.join(base_dir, \"reference\")\n",
    "crawled_dir = os.path.join(base_dir, \"crawled\")\n",
    "processed_dir = os.path.join(base_dir, \"processed\")\n",
    "baseline_embed_dir = os.path.join(base_dir, \"embeddings\", \"baseline\")\n",
    "issue_embed_dir = os.path.join(base_dir, \"embeddings\", \"issue\")\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "for dir_path in [crawled_dir, processed_dir, baseline_embed_dir, issue_embed_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "decd4add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKAX\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-JIaWGMA_-py3.11\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ChatOpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "âœ… HuggingFace ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# step3. ì„ë² ë”© ëª¨ë¸ ë° LLM ì´ˆê¸°í™”\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "# ğŸ’¡ LLM ì´ˆê¸°í™” (ìš”ì•½ ë° í‰ê°€ì— ì‚¬ìš©)\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    print(\"âœ… ChatOpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ChatOpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    llm = None\n",
    "\n",
    "print(\"âœ… HuggingFace ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ad70088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Baseline ë©”ëª¨ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# step4. Baseline ë©”ëª¨ë¦¬ êµ¬ì¶• (EU, OECD, UNESCO ë¬¸ì„œ)\n",
    "def build_baseline_memory():\n",
    "    \"\"\"ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ Baseline ë©”ëª¨ë¦¬ êµ¬ì¶•\"\"\"\n",
    "    baseline_docs = []\n",
    "    \n",
    "    # PDF íŒŒì¼ ë¡œë“œ\n",
    "    pdf_files = [\n",
    "        \"EU_AI_Act.pdf\",\n",
    "        \"OECD_Privacy_2024.pdf\", \n",
    "        \"UNESCO_Ethics_2021.pdf\"\n",
    "    ]\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(reference_dir, pdf_file)\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            loader = PyMuPDFLoader(pdf_path)\n",
    "            docs = loader.load()\n",
    "            print(f\"âœ… {pdf_file} ë¡œë“œ ì™„ë£Œ\")\n",
    "            \n",
    "            # ë©”íƒ€ë°ì´í„°ì— ë¬¸ì„œ íƒ€ì… ì¶”ê°€ ë° í˜ì´ì§€ ë²ˆí˜¸ ì •ë³´ í¬í•¨\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"document_type\"] = \"baseline\"\n",
    "                doc.metadata[\"source\"] = pdf_file\n",
    "                doc.metadata[\"page\"] = doc.metadata.get(\"page\", 0) + 1 # í˜ì´ì§€ ë²ˆí˜¸ëŠ” 1ë¶€í„° ì‹œì‘\n",
    "            baseline_docs.extend(docs)\n",
    "        else:\n",
    "            print(f\"âš ï¸ {pdf_file} íŒŒì¼ì´ ì§€ì •ëœ ê²½ë¡œì— ì—†ìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "    \n",
    "    if not baseline_docs:\n",
    "        print(\"âŒ Baseline ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. RAGê°€ Baseline ì¦ê±°ë¥¼ ì°¾ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        split_docs = [Document(page_content=\"No official baseline documents loaded.\", metadata={\"source\": \"N/A\", \"document_type\": \"baseline\", \"page\": 0})]\n",
    "    else:\n",
    "        # í…ìŠ¤íŠ¸ ë¶„í• \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        split_docs = text_splitter.split_documents(baseline_docs)\n",
    "    \n",
    "    # ChromaDBì— ì €ì¥\n",
    "    baseline_vectorstore = Chroma.from_documents(\n",
    "        documents=split_docs,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=baseline_embed_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Baseline ë©”ëª¨ë¦¬ êµ¬ì¶• ì™„ë£Œ ({len(split_docs)}ê°œ ì²­í¬)\")\n",
    "    return baseline_vectorstore\n",
    "\n",
    "print(\"âœ… Baseline ë©”ëª¨ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c485a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›¹ í¬ë¡¤ë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# step5. ì›¹ í¬ë¡¤ë§ í•¨ìˆ˜ ì •ì˜ (Tavily ì‚¬ìš©)\n",
    "def crawl_web_content(keywords: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Tavilyë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ìµœì‹  AI ìœ¤ë¦¬ ì´ìŠˆ ê´€ë ¨ ê¸°ì‚¬ í¬ë¡¤ë§\"\"\"\n",
    "    tavily = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))\n",
    "    crawled_data = []\n",
    "    search_queries = []\n",
    "    for keyword in keywords:\n",
    "        search_queries.extend([\n",
    "            f\"AI {keyword} ìœ¤ë¦¬ ì´ìŠˆ\",\n",
    "            f\"AI {keyword} í¸í–¥ì„± ë¬¸ì œ\",\n",
    "            f\"AI {keyword} ê°œì¸ì •ë³´ë³´í˜¸\",\n",
    "        ])\n",
    "    unique_queries = list(set(search_queries))[:5] # ìµœëŒ€ 5ê°œì˜ ê³ ìœ  ì¿¼ë¦¬ë¡œ ì œí•œ\n",
    "    \n",
    "    for query in unique_queries:\n",
    "        print(f\"     - Tavily ê²€ìƒ‰ ì¤‘: {query}...\")\n",
    "        try:\n",
    "            results = tavily.search(\n",
    "                query=query, \n",
    "                search_depth=\"advanced\", \n",
    "                max_results=5, \n",
    "                include_raw_content=True\n",
    "            )\n",
    "            for result in results.get(\"results\", []):\n",
    "                if result.get(\"content\"):\n",
    "                    crawled_data.append({\n",
    "                        \"title\": result.get(\"title\", \"No Title\"),\n",
    "                        \"content\": result[\"content\"],\n",
    "                        \"source\": result.get(\"url\", \"Unknown Source\"),\n",
    "                        \"url\": result.get(\"url\", \"\"),\n",
    "                        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                        \"category\": \"issue\"\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Tavily ê²€ìƒ‰ ì‹¤íŒ¨ ({query}): {e}\")\n",
    "            continue\n",
    "\n",
    "    # í•„í„°ë§ ë¡œì§ (300ì ì´ìƒ, ì„ ì •ì  í‘œí˜„ ì œê±°, ì¤‘ë³µ URL ì œê±°)\n",
    "    filtered_data = []\n",
    "    seen_urls = set()\n",
    "    for item in crawled_data:\n",
    "        if len(item[\"content\"]) >= 300:\n",
    "            if not any(word in item[\"content\"].lower() for word in [\"ì¶©ê²©\", \"í­ë¡œ\", \"clickbait\", \"ë…¼ë€ì˜\", \"ëŒ€ë°•\"]):\n",
    "                if item[\"url\"] not in seen_urls:\n",
    "                    filtered_data.append(item)\n",
    "                    seen_urls.add(item[\"url\"])\n",
    "\n",
    "    print(f\"âœ… ì›¹ í¬ë¡¤ë§ ì™„ë£Œ ({len(filtered_data)}ê°œ ë¬¸ì„œ)\")\n",
    "    return filtered_data\n",
    "\n",
    "print(\"âœ… ì›¹ í¬ë¡¤ë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e403121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Issue ë©”ëª¨ë¦¬ êµ¬ì¶• í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# step6. Issue ë©”ëª¨ë¦¬ êµ¬ì¶• (ì›¹ í¬ë¡¤ë§ ê²°ê³¼ë¥¼ RAGì— ì €ì¥)\n",
    "def build_issue_memory(keywords: List[str]):\n",
    "    \"\"\"ì›¹ í¬ë¡¤ë§ ê²°ê³¼ ê¸°ë°˜ Issue ë©”ëª¨ë¦¬ (Vectorstore) êµ¬ì¶•\"\"\"\n",
    "    crawled_data = crawl_web_content(keywords)\n",
    "    issue_docs = []\n",
    "    \n",
    "    for item in crawled_data:\n",
    "        doc = Document(\n",
    "            page_content=f\"[ì´ìŠˆ: {item['category']}] {item['title']}\\n\\n{item['content']}\",\n",
    "            metadata={\n",
    "                \"document_type\": \"issue\",\n",
    "                \"source\": item[\"source\"],\n",
    "                \"url\": item[\"url\"],\n",
    "                \"date\": item[\"date\"],\n",
    "                \"category\": item[\"category\"], # ì„ì‹œë¡œ 'issue'ë¡œ ì„¤ì •\n",
    "                \"title\": item[\"title\"]\n",
    "            }\n",
    "        )\n",
    "        issue_docs.append(doc)\n",
    "    \n",
    "    if issue_docs:\n",
    "        # Issue ë¬¸ì„œëŠ” ChromaDBì— ì €ì¥\n",
    "        issue_vectorstore = Chroma.from_documents(\n",
    "            documents=issue_docs,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=issue_embed_dir\n",
    "        )\n",
    "        print(f\"âœ… Issue ë©”ëª¨ë¦¬ êµ¬ì¶• ì™„ë£Œ ({len(issue_docs)}ê°œ ë¬¸ì„œ)\")\n",
    "        return issue_vectorstore\n",
    "    else:\n",
    "        print(\"âš ï¸ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Issue ë©”ëª¨ë¦¬ êµ¬ì¶• í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# ğŸ’¡ ì‹ ê·œ í•¨ìˆ˜ ì •ì˜: LLMì„ ì´ìš©í•œ ì¦ê±° ìš”ì•½\n",
    "def summarize_evidence_with_llm(docs: List[Document], query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"ê²€ìƒ‰ëœ Document ëª©ë¡ì„ LLMì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½í•˜ê³  ì„¸ë¶€ ì •ë³´ì™€ ê²°í•©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if not llm:\n",
    "        print(\"âš ï¸ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ìš”ì•½ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        return []\n",
    "\n",
    "    summarized_results = []\n",
    "    \n",
    "    summary_prompt_template = \"\"\"ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í•œêµ­ì–´ë¡œ 3ì¤„ ì´ë‚´ì˜ ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "    ì´ ìš”ì•½ì€ 'AI ì„œë¹„ìŠ¤ {query}ì˜ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬'ì— ëŒ€í•œ ê·¼ê±°ë¡œ ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "    ---\n",
    "    ë¬¸ì„œ ì¶œì²˜: {source} ({document_type}) {chunk_info}\n",
    "    ë¬¸ì„œ ë‚´ìš©: {content}\n",
    "    ---\n",
    "    ìš”ì•½:\"\"\"\n",
    "    summary_prompt = PromptTemplate(template=summary_prompt_template, input_variables=[\"query\", \"source\", \"document_type\", \"content\", \"chunk_info\"])\n",
    "\n",
    "    for doc in docs:\n",
    "        content = doc.page_content\n",
    "        source = doc.metadata.get(\"source\", doc.metadata.get(\"url\", \"Unknown\"))\n",
    "        doc_type = doc.metadata.get(\"document_type\", \"Unknown\")\n",
    "        category = doc.metadata.get(\"category\", \"N/A\")\n",
    "\n",
    "        # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¥¸ ì²­í¬ ì •ë³´ ì„¤ì •\n",
    "        if doc_type == \"baseline\":\n",
    "            chunk_info = f\"(í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}ì˜ ë‚´ìš©)\"\n",
    "            score = 0.8 # Baseline ê°€ì¤‘ì¹˜\n",
    "        else: # issue\n",
    "            chunk_info = \"(ì›¹ ê¸°ì‚¬ ì›ë¬¸)\"\n",
    "            score = 0.2 # Issue ê°€ì¤‘ì¹˜\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° ìš”ì•½ ìƒì„±\n",
    "        prompt_value = summary_prompt.invoke({\n",
    "            \"query\": query,\n",
    "            \"source\": source,\n",
    "            \"document_type\": doc_type,\n",
    "            \"content\": content,\n",
    "            \"chunk_info\": chunk_info\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # LLM í˜¸ì¶œ\n",
    "            summary_response = llm.invoke(prompt_value.to_string())\n",
    "            summary = summary_response.content.strip()\n",
    "        except Exception as e:\n",
    "            summary = f\"LLM ìš”ì•½ ì‹¤íŒ¨. Error: {e}\"\n",
    "        \n",
    "        # Risk Assessor ì—ì´ì „íŠ¸ì— ì „ë‹¬í•  ìƒì„¸ êµ¬ì¡°\n",
    "        summarized_results.append({\n",
    "            \"category\": category,\n",
    "            \"document_type\": doc_type,\n",
    "            \"source\": source,\n",
    "            \"chunk_info\": chunk_info, # PDF í˜ì´ì§€ ë˜ëŠ” ì›¹ ê¸°ì‚¬ ì—¬ë¶€\n",
    "            \"score\": score,\n",
    "            \"summary\": summary, \n",
    "            \"content_excerpt\": content[:300] + \"...\", # ì›ë¬¸ ë‚´ìš©ì˜ ì¼ë¶€ (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡)\n",
    "            \"full_content\": content # Risk Assessorì—ì„œ í•„ìš”í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ì „ì²´ ì›ë¬¸ë„ ì „ë‹¬\n",
    "        })\n",
    "        \n",
    "    return summarized_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a131f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¦ê±° ìˆ˜ì§‘ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# step7. ì¦ê±° ìˆ˜ì§‘ í•¨ìˆ˜ ì •ì˜ (ê°€ì¤‘ì¹˜ 8:2 ì ìš©)\n",
    "def collect_evidence(service_profile: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ì„œë¹„ìŠ¤ í”„ë¡œíŒŒì¼ ê¸°ë°˜ ì¦ê±° ìˆ˜ì§‘ (Baseline 0.8 : Issue 0.2)\n",
    "    - Risk Assessorì—ê²Œ ì „ë‹¬í•  ì¦ê±° ì†ŒìŠ¤ ëª©ë¡ ë° ê°€ì¤‘ì¹˜ ì ìˆ˜, ìš”ì•½ í¬í•¨\n",
    "    \"\"\"\n",
    "    \n",
    "    service_name = service_profile.get(\"service_name\", \"\")\n",
    "    # ğŸ’¡ Service Profilerì—ì„œ ë³€ê²½ëœ í‚¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •\n",
    "    risk_categories = service_profile.get(\"diagnosed_risk_categories\", []) \n",
    "    service_type = service_profile.get(\"service_type\", \"\")\n",
    "    \n",
    "    print(f\"\\nğŸ” ì¦ê±° ìˆ˜ì§‘ ì‹œì‘: {service_name}\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ êµ¬ì¶•\n",
    "    baseline_vectorstore = build_baseline_memory()\n",
    "    issue_vectorstore = build_issue_memory(risk_categories)\n",
    "    \n",
    "    evidence_results = {\n",
    "        \"query\": service_name,\n",
    "        \"weights\": {\"baseline\": 0.8, \"issue\": 0.2},\n",
    "        \"scores\": {},\n",
    "        \"baseline_sources\": [],\n",
    "        \"issue_sources\": []\n",
    "    }\n",
    "    \n",
    "    all_docs_to_summarize = []\n",
    "    \n",
    "    # 1. ê° ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬ë³„ ì¦ê±° ê²€ìƒ‰\n",
    "    for category in risk_categories:\n",
    "        \n",
    "        # Baseline ê²€ìƒ‰ ì¿¼ë¦¬ ê°•í™”\n",
    "        baseline_query = f\"{service_name} {category} ë¦¬ìŠ¤í¬ {service_type} (EU AI Act, OECD, UNESCO ìœ¤ë¦¬ ê¸°ì¤€)\"\n",
    "        issue_query = f\"ìµœì‹  ë‰´ìŠ¤ ë…¼ë¬¸ AI {service_name} {category} ë¬¸ì œ\"\n",
    "        \n",
    "        print(f\"\\n     ğŸ“Š {category.upper()} ë¦¬ìŠ¤í¬ ê²€ìƒ‰ ì¤‘...\")\n",
    "        \n",
    "        # Baseline ê²€ìƒ‰\n",
    "        baseline_docs = baseline_vectorstore.similarity_search(baseline_query, k=3)\n",
    "        \n",
    "        # Issue ê²€ìƒ‰\n",
    "        issue_docs = []\n",
    "        if issue_vectorstore:\n",
    "            issue_docs = issue_vectorstore.similarity_search(issue_query, k=2)\n",
    "            \n",
    "        # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ìš”ì•½ ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„° ë¶€ì—¬)\n",
    "        for doc in baseline_docs:\n",
    "            doc.metadata['category'] = category\n",
    "            all_docs_to_summarize.append(doc)\n",
    "        for doc in issue_docs:\n",
    "            doc.metadata['category'] = category\n",
    "            all_docs_to_summarize.append(doc)\n",
    "            \n",
    "        # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì°¸ê³ ìš©)\n",
    "        baseline_weight = 0.8\n",
    "        issue_weight = 0.2 if issue_docs else 0.0\n",
    "        total_score = (len(baseline_docs) > 0) * baseline_weight + (len(issue_docs) > 0) * issue_weight\n",
    "        evidence_results[\"scores\"][category] = total_score\n",
    "        \n",
    "        print(f\" - ê²€ìƒ‰ëœ Baseline ì²­í¬: {len(baseline_docs)}ê°œ\")\n",
    "        print(f\" - ê²€ìƒ‰ëœ Issue ë¬¸ì„œ: {len(issue_docs)}ê°œ\")\n",
    "\n",
    "    print(\"\\nğŸ“ ê²€ìƒ‰ëœ ì¦ê±°ë“¤ì„ LLMì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ì¤‘...\")\n",
    "    \n",
    "    # 2. í†µí•© ìš”ì•½ ë° ë°ì´í„° êµ¬ì¡°í™”\n",
    "    summarized_evidences = summarize_evidence_with_llm(all_docs_to_summarize, service_name)\n",
    "    \n",
    "    # 3. ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    for evidence in summarized_evidences:\n",
    "        if evidence['document_type'] == 'baseline':\n",
    "            evidence_results[\"baseline_sources\"].append(evidence)\n",
    "        elif evidence['document_type'] == 'issue':\n",
    "            evidence_results[\"issue_sources\"].append(evidence)\n",
    "    \n",
    "    print(f\"\\nâœ… ì¦ê±° ìˆ˜ì§‘ ë° ìš”ì•½ ì™„ë£Œ!\")\n",
    "    return evidence_results\n",
    "\n",
    "print(\"âœ… ì¦ê±° ìˆ˜ì§‘ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a4c0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ” Evidence Collector ì‹œì‘...\n",
      "============================================================\n",
      "\n",
      "ğŸ“ ë¶„ì„í•  ì„œë¹„ìŠ¤: ì±„ìš© ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬ ì í•©í•œ í›„ë³´ìë¥¼ ì¶”ì²œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤....\n",
      "\n",
      "ğŸ” ì¦ê±° ìˆ˜ì§‘ ì‹œì‘: ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
      "âœ… EU_AI_Act.pdf ë¡œë“œ ì™„ë£Œ\n",
      "âœ… OECD_Privacy_2024.pdf ë¡œë“œ ì™„ë£Œ\n",
      "âœ… UNESCO_Ethics_2021.pdf ë¡œë“œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Baseline ë©”ëª¨ë¦¬ êµ¬ì¶• ì™„ë£Œ (2075ê°œ ì²­í¬)\n",
      "     - Tavily ê²€ìƒ‰ ì¤‘: AI bias í¸í–¥ì„± ë¬¸ì œ...\n",
      "     - Tavily ê²€ìƒ‰ ì¤‘: AI privacy í¸í–¥ì„± ë¬¸ì œ...\n",
      "     - Tavily ê²€ìƒ‰ ì¤‘: AI transparency ê°œì¸ì •ë³´ë³´í˜¸...\n",
      "     - Tavily ê²€ìƒ‰ ì¤‘: AI privacy ìœ¤ë¦¬ ì´ìŠˆ...\n",
      "     - Tavily ê²€ìƒ‰ ì¤‘: AI bias ìœ¤ë¦¬ ì´ìŠˆ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›¹ í¬ë¡¤ë§ ì™„ë£Œ (21ê°œ ë¬¸ì„œ)\n",
      "âœ… Issue ë©”ëª¨ë¦¬ êµ¬ì¶• ì™„ë£Œ (21ê°œ ë¬¸ì„œ)\n",
      "\n",
      "     ğŸ“Š BIAS ë¦¬ìŠ¤í¬ ê²€ìƒ‰ ì¤‘...\n",
      " - ê²€ìƒ‰ëœ Baseline ì²­í¬: 3ê°œ\n",
      " - ê²€ìƒ‰ëœ Issue ë¬¸ì„œ: 2ê°œ\n",
      "\n",
      "     ğŸ“Š PRIVACY ë¦¬ìŠ¤í¬ ê²€ìƒ‰ ì¤‘...\n",
      " - ê²€ìƒ‰ëœ Baseline ì²­í¬: 3ê°œ\n",
      " - ê²€ìƒ‰ëœ Issue ë¬¸ì„œ: 2ê°œ\n",
      "\n",
      "     ğŸ“Š TRANSPARENCY ë¦¬ìŠ¤í¬ ê²€ìƒ‰ ì¤‘...\n",
      " - ê²€ìƒ‰ëœ Baseline ì²­í¬: 3ê°œ\n",
      " - ê²€ìƒ‰ëœ Issue ë¬¸ì„œ: 2ê°œ\n",
      "\n",
      "ğŸ“ ê²€ìƒ‰ëœ ì¦ê±°ë“¤ì„ LLMì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ì¤‘...\n",
      "\n",
      "âœ… ì¦ê±° ìˆ˜ì§‘ ë° ìš”ì•½ ì™„ë£Œ!\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š ì¦ê±° ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ë° ë‹¤ìŒ ì—ì´ì „íŠ¸ ì „ë‹¬ ë‚´ìš©\n",
      "============================================================\n",
      " Â - ì„œë¹„ìŠ¤ëª…: ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
      " Â - ê°€ì¤‘ì¹˜: Baseline 0.8 : Issue 0.2\n",
      " Â - ìˆ˜ì§‘ëœ ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: ['bias', 'privacy', 'transparency']\n",
      "\n",
      "------------------------------------------------------------\n",
      "ğŸš¨ Risk Assessorì— ì „ë‹¬ë˜ëŠ” ë°ì´í„° êµ¬ì¡° ìš”ì•½ (ì²« ë²ˆì§¸ ì¦ê±° ì˜ˆì‹œ)\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Baseline ê·¼ê±° ì˜ˆì‹œ]\n",
      " Â - ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: BIAS\n",
      " Â - ì¶œì²˜: UNESCO_Ethics_2021.pdf (í˜ì´ì§€ 40ì˜ ë‚´ìš©)\n",
      " Â - **ìš”ì•½ (í•µì‹¬ ê·¼ê±°):** AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ UNESCOì˜ ì •ì±… ê¶Œê³ ì‚¬í•­ì— ë”°ë¼ ìœ¤ë¦¬ì  ê¸°ì¤€ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ì´ë¥¼ ìœ„í•´ ê²½í—˜ ê³µìœ  ë©”ì»¤ë‹ˆì¦˜ê³¼ AI ê·œì œ ìƒŒë“œë°•ìŠ¤ê°€ í•„ìš”í•˜ë‹¤. ì´ëŸ¬í•œ ë„êµ¬ë“¤ì€ AI ê´€ë ¨ ì£¼ì²´ë“¤ì´ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì‹œìŠ¤í…œì˜ ì„¤ê³„ì™€ ìš´ì˜ì—ì„œ ìœ¤ë¦¬ì  ê³ ë ¤ê°€ í•„ìˆ˜ì ì´ë‹¤.\n",
      " Â - ì›ë¬¸ ë‚´ìš© (ì¼ë¶€): across UNESCOâ€™s areas of competence, an experience-\n",
      "sharing mechanism, AI regulatory sandboxes, and an \n",
      "assessment guide for all AI actors to evaluate their \n",
      "adherence to policy recommendations mentioned in \n",
      "this document....\n",
      "\n",
      "[Issue ê·¼ê±° ì˜ˆì‹œ]\n",
      " Â - ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: BIAS\n",
      " Â - ì¶œì²˜: https://m.blog.naver.com/edawoon/221835492705 (N/A) (ì›¹ ê¸°ì‚¬ ì›ë¬¸)\n",
      " Â - **ìš”ì•½ (ì‚¬íšŒì  ë°˜ì‘):** AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì•Œê³ ë¦¬ì¦˜ì˜ í¸í–¥ì„± ë¬¸ì œë¡œ ì¸í•´ ë¶ˆê³µì •í•œ ê²°ì •ì´ ë‚´ë ¤ì§ˆ ìœ„í—˜ì´ ìˆë‹¤. ì¸ê³µì§€ëŠ¥ì´ ì‚¬ëŒì˜ í¸ê²¬ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì´ ìˆì§€ë§Œ, ì—¬ì „íˆ ì¸ê°„ì˜ íŒë‹¨ì´ í•„ìš”í•˜ë©°, ì‚¬íšŒì  ë§¥ë½ê³¼ ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•ì˜ ë¬¸ì œë¥¼ ê³ ë ¤í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ ê³µì •ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìˆ˜ì ì´ë‹¤.\n",
      " Â - ì›ë¬¸ ë‚´ìš© (ì¼ë¶€): [ì´ìŠˆ: issue] [ë§¥í‚¨ì§€ ë³´ê³ ì„œ] ì¸ê³µì§€ëŠ¥ì˜ í¸í–¥ì„±(bias)ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²•\n",
      "\n",
      "MGI-Tackling-bias-in-AI-June-2019.pdf\n",
      "\n",
      "íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
      "\n",
      "<ì¸ê³µì§€ëŠ¥ ê²½ê³„ì„ : ì¸ê³µì§€ëŠ¥ ë° ì‚¬ëŒë“¤ì˜ í¸ê²¬(Notes from the AI frontier: Tackling bias in AI (and in humans))>ì—ì„œëŠ” ì•Œê³ ë¦¬ì¦˜ì´ ì‚¬ëŒë“¤ì˜ í¸ê²¬ìœ¼ë¡œ ë°œìƒí•œ ë¶ˆê³µì •í•œ ì°¨ì´ë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ê³³ê³¼ ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ ì¸í•´ í™•ì¥ë  ìˆ˜ ìˆëŠ” ë¶ˆê³µì •í•œ í¸ê²¬ì„ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•˜ê¸° ìœ„í•œ ê°œìš”ë¥¼ ë³´ì—¬ì¤€ë‹¤.\n",
      "\n",
      "â€‹\n",
      "\n",
      "â€‹...\n",
      "\n",
      "------------------------------------------------------------\n",
      "ğŸ”— ìµœì¢…ì ìœ¼ë¡œ 15ê°œì˜ ìƒì„¸ ì¦ê±°ê°€ Risk Assessorë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# step8. í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” Evidence Collector ì‹œì‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ğŸ’¡ Service Profilerì—ì„œ ë°›ì€ ê²°ê³¼ (ì˜ˆì‹œ, ë³€ê²½ëœ í‚¤ ë°˜ì˜)\n",
    "test_service_profile = {\n",
    "    \"service_name\": \"ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\",\n",
    "    \"service_type\": \"recruitment system\", \n",
    "    \"description\": \"ì±„ìš© ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬ ì í•©í•œ í›„ë³´ìë¥¼ ì¶”ì²œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\",\n",
    "    \"diagnosed_risk_categories\": [\"bias\", \"privacy\", \"transparency\"] # ë³€ê²½ëœ í‚¤\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“ ë¶„ì„í•  ì„œë¹„ìŠ¤: {test_service_profile['description']}...\")\n",
    "\n",
    "# ì¦ê±° ìˆ˜ì§‘ ì‹¤í–‰\n",
    "evidence_result = collect_evidence(test_service_profile)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ì¦ê±° ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ë° ë‹¤ìŒ ì—ì´ì „íŠ¸ ì „ë‹¬ ë‚´ìš©\")\n",
    "print(\"=\"*60)\n",
    "print(f\" Â - ì„œë¹„ìŠ¤ëª…: {evidence_result['query']}\")\n",
    "print(f\" Â - ê°€ì¤‘ì¹˜: Baseline {evidence_result['weights']['baseline']} : Issue {evidence_result['weights']['issue']}\")\n",
    "print(f\" Â - ìˆ˜ì§‘ëœ ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: {list(evidence_result['scores'].keys())}\")\n",
    "\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(\"ğŸš¨ Risk Assessorì— ì „ë‹¬ë˜ëŠ” ë°ì´í„° êµ¬ì¡° ìš”ì•½ (ì²« ë²ˆì§¸ ì¦ê±° ì˜ˆì‹œ)\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# ì „ë‹¬ë  ë°ì´í„° êµ¬ì¡° ì˜ˆì‹œ ì¶œë ¥ (ì²« ë²ˆì§¸ Baseline ì†ŒìŠ¤ì™€ ì²« ë²ˆì§¸ Issue ì†ŒìŠ¤)\n",
    "if evidence_result['baseline_sources']:\n",
    "    b_src = evidence_result['baseline_sources'][0]\n",
    "    print(\"\\n[Baseline ê·¼ê±° ì˜ˆì‹œ]\")\n",
    "    print(f\" Â - ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: {b_src['category'].upper()}\")\n",
    "    print(f\" Â - ì¶œì²˜: {b_src['source']} {b_src['chunk_info']}\")\n",
    "    print(f\" Â - **ìš”ì•½ (í•µì‹¬ ê·¼ê±°):** {b_src['summary']}\")\n",
    "    print(f\" Â - ì›ë¬¸ ë‚´ìš© (ì¼ë¶€): {b_src['content_excerpt']}\")\n",
    "\n",
    "if evidence_result['issue_sources']:\n",
    "    i_src = evidence_result['issue_sources'][0]\n",
    "    print(\"\\n[Issue ê·¼ê±° ì˜ˆì‹œ]\")\n",
    "    print(f\" Â - ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: {i_src['category'].upper()}\")\n",
    "    print(f\" Â - ì¶œì²˜: {i_src['source']} ({i_src.get('url', 'N/A')}) {i_src['chunk_info']}\")\n",
    "    print(f\" Â - **ìš”ì•½ (ì‚¬íšŒì  ë°˜ì‘):** {i_src['summary']}\")\n",
    "    print(f\" Â - ì›ë¬¸ ë‚´ìš© (ì¼ë¶€): {i_src['content_excerpt']}\")\n",
    "\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(f\"ğŸ”— ìµœì¢…ì ìœ¼ë¡œ {len(evidence_result['baseline_sources']) + len(evidence_result['issue_sources'])}ê°œì˜ ìƒì„¸ ì¦ê±°ê°€ Risk Assessorë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff60b438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ğŸš€ Risk Assessor ì—ì´ì „íŠ¸ ì „ë‹¬ ë‚´ìš© ìµœì¢… í™•ì¸"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„œë¹„ìŠ¤ëª…: ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
      "ê°€ì¤‘ì¹˜: Baseline 0.8 : Issue 0.2\n",
      "ìˆ˜ì§‘ëœ ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: ['bias', 'privacy', 'transparency']\n",
      "ì´ ì „ë‹¬ ì¦ê±° ê°œìˆ˜: 15ê°œ\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ“š 1. Baseline ì¦ê±° (ë²•ì /ìœ¤ë¦¬ ê¸°ì¤€ ê·¼ê±°)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**[1. BIAS - Baseline]**\n",
      "- **ì¶œì²˜:** UNESCO_Ethics_2021.pdf (í˜ì´ì§€ 40ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ UNESCOì˜ ì •ì±… ê¶Œê³ ì‚¬í•­ì— ë”°ë¼ ìœ¤ë¦¬ì  ê¸°ì¤€ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ì´ë¥¼ ìœ„í•´ ê²½í—˜ ê³µìœ  ë©”ì»¤ë‹ˆì¦˜ê³¼ AI ê·œì œ ìƒŒë“œë°•ìŠ¤ê°€ í•„ìš”í•˜ë‹¤. ì´ëŸ¬í•œ ë„êµ¬ë“¤ì€ AI ê´€ë ¨ ì£¼ì²´ë“¤ì´ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì‹œìŠ¤í…œì˜ ì„¤ê³„ì™€ ìš´ì˜ì—ì„œ ìœ¤ë¦¬ì  ê³ ë ¤ê°€ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > across UNESCOâ€™s areas of competence, an experience-\n",
      "sharing mechanism, AI regulatory sandboxes, and an \n",
      "assessment guide for all AI actors to evaluate their \n",
      "adherence to policy recommendations mentioned in \n",
      "this document....\n",
      "---\n",
      "\n",
      "**[2. BIAS - Baseline]**\n",
      "- **ì¶œì²˜:** EU_AI_Act.pdf (í˜ì´ì§€ 14ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì‹œì¥ì— ì¶œì‹œë˜ê¸° ì „ì— ìœ¤ë¦¬ì  í‰ê°€ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê³ , ì´ë¥¼ êµ­ê°€ ë‹¹êµ­ì— ì œê³µí•´ì•¼ í•˜ë©°, EU ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡í•´ì•¼ í•˜ëŠ” ì˜ë¬´ê°€ ìˆë‹¤. ì´ëŸ¬í•œ ê·œì •ì€ ì‹œìŠ¤í…œì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•˜ê³  íˆ¬ëª…ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤. ë”°ë¼ì„œ, í•´ë‹¹ ì‹œìŠ¤í…œì˜ ê°œë°œ ë° ìš´ì˜ ì‹œ ì² ì €í•œ ìœ¤ë¦¬ì  ê²€í† ê°€ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > to above should draw up documentation of the assessment before that system is placed on the market or put into \n",
      "service and should provide that documentation to national competent authorities upon request. Such a provider \n",
      "should be obliged to register the AI system in the EU database established un...\n",
      "---\n",
      "\n",
      "**[3. BIAS - Baseline]**\n",
      "- **ì¶œì²˜:** EU_AI_Act.pdf (í˜ì´ì§€ 15ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì‹œì¥ì— ì¶œì‹œë˜ê¸° ì „ì— ìœ¤ë¦¬ì  í‰ê°€ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê³ , ìš”ì²­ ì‹œ êµ­ê°€ ë‹¹êµ­ì— ì œì¶œí•´ì•¼ í•œë‹¤. ë˜í•œ, í•´ë‹¹ ì‹œìŠ¤í…œì€ EU ê·œì •ì— ë”°ë¼ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡í•´ì•¼ í•˜ë©°, ì´ëŠ” ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ ê´€ë¦¬ì˜ í•„ìˆ˜ ì¡°ê±´ì´ë‹¤. ì´ëŸ¬í•œ ì ˆì°¨ëŠ” ì‹œìŠ¤í…œì˜ íˆ¬ëª…ì„±ê³¼ ì±…ì„ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•œë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > to above should draw up documentation of the assessment before that system is placed on the market or put into \n",
      "service and should provide that documentation to national competent authorities upon request. Such a provider \n",
      "should be obliged to register the AI system in the EU database established un...\n",
      "---\n",
      "\n",
      "**[4. PRIVACY - Baseline]**\n",
      "- **ì¶œì²˜:** OECD_Privacy_2024.pdf (í˜ì´ì§€ 40ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > OECDì˜ ê°œì¸ì •ë³´ ë³´í˜¸ ê°€ì´ë“œë¼ì¸ì€ AIì— íŠ¹í™”ë˜ì§€ ì•Šì€ í”„ë¼ì´ë²„ì‹œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ë©°, AIì™€ í”„ë¼ì´ë²„ì‹œ ê°„ì˜ ì—°ê³„ë¥¼ ìœ„í•œ ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤ê³  ê°•ì¡°í•œë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ëŠ” ë° ì¤‘ìš”í•œ ê¸°ì´ˆê°€ ë  ìˆ˜ ìˆë‹¤. AI ìƒì•  ì£¼ê¸° í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•©í•¨ìœ¼ë¡œì¨ ë³´ë‹¤ í¬ê´„ì ì¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ ê°€ëŠ¥í•´ì§„ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > the OECD Privacy Guidelines, and presents a framework for privacy risk management which is not AI-\n",
      "specific, in keeping with the approach of the Guidelines (OECD, 2023[44]). Further work bridging AI and \n",
      "privacy works could incorporate the AI lifecycle framework presented in OECD reports (OECD, 2022...\n",
      "---\n",
      "\n",
      "**[5. PRIVACY - Baseline]**\n",
      "- **ì¶œì²˜:** OECD_Privacy_2024.pdf (í˜ì´ì§€ 41ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > OECDì˜ ê°œì¸ì •ë³´ ë³´í˜¸ ê°€ì´ë“œë¼ì¸ì€ AIì— íŠ¹í™”ë˜ì§€ ì•Šì€ í”„ë¼ì´ë²„ì‹œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ë©°, AIì™€ í”„ë¼ì´ë²„ì‹œ ê°„ì˜ ì—°ê³„ë¥¼ ìœ„í•œ ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤ê³  ê°•ì¡°í•œë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•˜ëŠ” ë° ì¤‘ìš”í•œ ê¸°ì´ˆê°€ ëœë‹¤. ë”°ë¼ì„œ, AI ìƒì•  ì£¼ê¸° í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•©í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > the OECD Privacy Guidelines, and presents a framework for privacy risk management which is not AI-\n",
      "specific, in keeping with the approach of the Guidelines (OECD, 2023[44]). Further work bridging AI and \n",
      "privacy works could incorporate the AI lifecycle framework presented in OECD reports (OECD, 2022...\n",
      "---\n",
      "\n",
      "**[6. PRIVACY - Baseline]**\n",
      "- **ì¶œì²˜:** OECD_Privacy_2024.pdf (í˜ì´ì§€ 41ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ OECDì˜ ê°œì¸ì •ë³´ ë³´í˜¸ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ AIì™€ ê°œì¸ì •ë³´ ë³´í˜¸ ê°„ì˜ ì—°ê³„ë¥¼ ê³ ë ¤í•´ì•¼ í•˜ë©°, AI ìƒì•  ì£¼ê¸° í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•©í•˜ì—¬ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•´ì•¼ í•œë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ AI ê´€ë ¨ ë²•ë¥  ë° ê·œì œ, ì˜ˆë¥¼ ë“¤ì–´ EU AI ë²•ì•ˆê³¼ë„ ì¼ì¹˜í•œë‹¤. ë”°ë¼ì„œ, ì‹œìŠ¤í…œ ì„¤ê³„ ì‹œ ìœ¤ë¦¬ì  ê³ ë ¤ê°€ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > the OECD Privacy Guidelines, and presents a framework for privacy risk management which is not AI-\n",
      "specific, in keeping with the approach of the Guidelines (OECD, 2023[44]). Further work bridging AI and \n",
      "privacy works could incorporate the AI lifecycle framework presented in OECD reports (OECD, 2022...\n",
      "---\n",
      "\n",
      "**[7. TRANSPARENCY - Baseline]**\n",
      "- **ì¶œì²˜:** EU_AI_Act.pdf (í˜ì´ì§€ 82ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì¸ê³µì§€ëŠ¥ì˜ íˆ¬ëª…ì„± ì˜ë¬´ë¥¼ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ì¸ìœ„ì ìœ¼ë¡œ ìƒì„±ë˜ê±°ë‚˜ ì¡°ì‘ëœ ì½˜í…ì¸ ì˜ íƒì§€ ë° ë¼ë²¨ë§ì— ëŒ€í•œ ì‹¤ì²œ ê°•ë ¹ì„ ë§ˆë ¨í•´ì•¼ í•œë‹¤. ì´ëŸ¬í•œ ì˜ë¬´ë¥¼ ì´í–‰í•˜ì§€ ì•Šì„ ê²½ìš° ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ê´€ë ¨ ë²•ê·œë¥¼ ì¤€ìˆ˜í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > prejudice to other transparency obligations laid down in Union or national law for deployers of AI systems.\n",
      "7.\n",
      "The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level to facilitate the effective \n",
      "implementation of the obligations regarding the detection and la...\n",
      "---\n",
      "\n",
      "**[8. TRANSPARENCY - Baseline]**\n",
      "- **ì¶œì²˜:** EU_AI_Act.pdf (í˜ì´ì§€ 83ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì¸ê³µì§€ëŠ¥ì˜ íˆ¬ëª…ì„± ì˜ë¬´ë¥¼ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ì¸ìœ„ì ìœ¼ë¡œ ìƒì„±ë˜ê±°ë‚˜ ì¡°ì‘ëœ ì½˜í…ì¸ ì˜ íƒì§€ ë° ë¼ë²¨ë§ì— ëŒ€í•œ ì‹¤ì²œ ê°•ë ¹ì„ ë§ˆë ¨í•´ì•¼ í•œë‹¤. ì´ëŸ¬í•œ ì˜ë¬´ë¥¼ ì´í–‰í•˜ì§€ ì•Šì„ ê²½ìš° ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ê´€ë ¨ ë²•ê·œë¥¼ ì¤€ìˆ˜í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > prejudice to other transparency obligations laid down in Union or national law for deployers of AI systems.\n",
      "7.\n",
      "The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level to facilitate the effective \n",
      "implementation of the obligations regarding the detection and la...\n",
      "---\n",
      "\n",
      "**[9. TRANSPARENCY - Baseline]**\n",
      "- **ì¶œì²˜:** EU_AI_Act.pdf (í˜ì´ì§€ 83ì˜ ë‚´ìš©)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.8\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì¸ê³µì§€ëŠ¥ì˜ íˆ¬ëª…ì„± ì˜ë¬´ë¥¼ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ì¸ìœ„ì ìœ¼ë¡œ ìƒì„±ë˜ê±°ë‚˜ ì¡°ì‘ëœ ì½˜í…ì¸ ì˜ íƒì§€ ë° ë¼ë²¨ë§ì— ëŒ€í•œ ì‹¤íš¨ì„± ìˆëŠ” ì‹¤í–‰ì„ ìœ„í•œ í–‰ë™ ê°•ë ¹ì´ í•„ìš”í•˜ë‹¤. ì´ëŸ¬í•œ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ëŠ” ë²•ì  ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ì§€ ëª»í•  ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì‹œìŠ¤í…œì˜ ì„¤ê³„ì™€ ìš´ì˜ì—ì„œ íˆ¬ëª…ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > prejudice to other transparency obligations laid down in Union or national law for deployers of AI systems.\n",
      "7.\n",
      "The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level to facilitate the effective \n",
      "implementation of the obligations regarding the detection and la...\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ“° 2. Issue ì¦ê±° (ìµœì‹  ì‚¬íšŒì  ë°˜ì‘ ê·¼ê±°)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**[1. BIAS - Issue]**\n",
      "- **ì¶œì²˜:** https://m.blog.naver.com/edawoon/221835492705 (URL: N/A)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.2\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì•Œê³ ë¦¬ì¦˜ì˜ í¸í–¥ì„± ë¬¸ì œë¡œ ì¸í•´ ë¶ˆê³µì •í•œ ê²°ì •ì´ ë‚´ë ¤ì§ˆ ìœ„í—˜ì´ ìˆë‹¤. ì¸ê³µì§€ëŠ¥ì´ ì‚¬ëŒì˜ í¸ê²¬ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì´ ìˆì§€ë§Œ, ì—¬ì „íˆ ì¸ê°„ì˜ íŒë‹¨ì´ í•„ìš”í•˜ë©°, ì‚¬íšŒì  ë§¥ë½ê³¼ ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•ì˜ ë¬¸ì œë¥¼ ê³ ë ¤í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ ê³µì •ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > [ì´ìŠˆ: issue] [ë§¥í‚¨ì§€ ë³´ê³ ì„œ] ì¸ê³µì§€ëŠ¥ì˜ í¸í–¥ì„±(bias)ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²•\n",
      "\n",
      "MGI-Tackling-bias-in-AI-June-2019.pdf\n",
      "\n",
      "íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
      "\n",
      "<ì¸ê³µì§€ëŠ¥ ê²½ê³„ì„ : ì¸ê³µì§€ëŠ¥ ë° ì‚¬ëŒë“¤ì˜ í¸ê²¬(Notes from the AI frontier: Tackling bias in AI (and in humans))>ì—ì„œëŠ” ì•Œê³ ë¦¬ì¦˜ì´ ì‚¬ëŒë“¤ì˜ í¸ê²¬ìœ¼ë¡œ ë°œìƒí•œ ë¶ˆê³µì •í•œ ì°¨ì´ë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ê³³ê³¼ ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ ì¸í•´ í™•ì¥ë  ìˆ˜ ìˆëŠ” ë¶ˆê³µì •í•œ í¸ê²¬ì„ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•˜ê¸° ìœ„í•œ ê°œìš”ë¥¼ ë³´ì—¬ì¤€ë‹¤.\n",
      "\n",
      "â€‹\n",
      "\n",
      "â€‹...\n",
      "---\n",
      "\n",
      "**[2. BIAS - Issue]**\n",
      "- **ì¶œì²˜:** https://dailyan.com/news/article.html?no=731402 (URL: N/A)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.2\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ í¸í–¥ëœ í•™ìŠµ ë°ì´í„°ë¡œ ì¸í•´ ì°¨ë³„ì  ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì‚¬íšŒì  ë¶ˆí‰ë“±ì„ ì‹¬í™”ì‹œí‚¬ ìœ„í—˜ì´ ìˆë‹¤. ë˜í•œ, AIì˜ ê²°ì •ì— ëŒ€í•œ ì±…ì„ ì†Œì¬ê°€ ë¶ˆëª…í™•í•˜ì—¬ ë²•ì  ë° ìœ¤ë¦¬ì  í˜¼ë€ì„ ì•¼ê¸°í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ìœ¤ë¦¬ì  ê³ ë ¤ì™€ íˆ¬ëª…ì„±ì„ ê°•í™”í•˜ê³ , ëª…í™•í•œ ê¸°ì¤€ì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì´ë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > [ì´ìŠˆ: issue] AI ê°œë°œì˜ ìœ¤ë¦¬ì  ë¬¸ì œì  ì‹¬í™”: ì±…ì„ ì†Œì¬ì™€ í¸í–¥ì„± ë…¼ë€ í™•ëŒ€\n",
      "\n",
      "í˜ì´ìŠ¤ë¶\n",
      " ì—‘ìŠ¤\n",
      " ì¹´ì¹´ì˜¤í†¡\n",
      " ë„¤ì´ë²„ë¸”ë¡œê·¸\n",
      "\n",
      "### ê¸‰ì†í•œ AI ë°œì „ ì†ì—ì„œ ìœ¤ë¦¬ì  ë¬¸ì œê°€ ì‚¬íšŒì  ë…¼ìŸìœ¼ë¡œ í™•ëŒ€ë˜ëŠ” í˜„í™© ë¶„ì„\n",
      "\n",
      "ë°ì¼ë¦¬ì—°í•© (SNSJTV. íƒ€ì„ì¦ˆM) ê¹€ë¯¼ì œ ê¸°ì | ìµœê·¼ ê¸‰ì†ë„ë¡œ ë°œì „í•˜ëŠ” ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ ì€ í¸ë¦¬í•¨ê³¼ íš¨ìœ¨ì„±ì„ ì œê³µí•˜ì§€ë§Œ ë™ì‹œì— ì‹¬ê°í•œ ìœ¤ë¦¬ì  ë¬¸ì œë¥¼ ì•¼ê¸°í•œë‹¤ëŠ” ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤.\n",
      "\n",
      "AI ê°œë°œ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” í¸í–¥ì„± ë¬¸ì œëŠ” ì‹¬ê°í•œ ì‚¬íšŒì  ë¶ˆí‰ë“±ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤. AI ì•Œê³ ë¦¬ì¦˜ì€ í•™ìŠµ ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ”ë°, ì´ ...\n",
      "---\n",
      "\n",
      "**[3. PRIVACY - Issue]**\n",
      "- **ì¶œì²˜:** https://ovic.vic.gov.au/privacy/resources-for-organisations/artificial-intelligence-and-privacy-issues-and-challenges/ (URL: N/A)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.2\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ê°œë°œìì˜ ê°œì¸ì  í¸í–¥ì´ ì‹œìŠ¤í…œì— ë°˜ì˜ë  ìœ„í—˜ì´ ìˆìœ¼ë©°, ì´ëŠ” ì°¨ë³„ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, AIì˜ ë¶ˆíˆ¬ëª…í•œ ê²°ê³¼ëŠ” ì •ë¶€ ê¸°ê´€ì˜ ì˜ì‚¬ê²°ì •ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê°œì¸ì •ë³´ ë³´í˜¸ì™€ ì°¨ë³„ ë°©ì§€ì˜ ê· í˜•ì„ ì¬ì¡°ëª…í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > [ì´ìŠˆ: issue] Artificial Intelligence and Privacy â€“ Issues and Challenges\n",
      "\n",
      "Further, those building the systems may unknowingly introduce their own human biases into the functionality. Because AI challenges the ability of information privacy to operate as it has done historically, the safeguard against...\n",
      "---\n",
      "\n",
      "**[4. PRIVACY - Issue]**\n",
      "- **ì¶œì²˜:** https://ovic.vic.gov.au/privacy/resources-for-organisations/artificial-intelligence-and-privacy-issues-and-challenges/ (URL: N/A)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.2\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ê°œë°œìì˜ ê°œì¸ì  í¸í–¥ì´ ì‹œìŠ¤í…œì— ë°˜ì˜ë  ìœ„í—˜ì´ ìˆìœ¼ë©°, ì´ëŠ” ì°¨ë³„ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, AIì˜ ë¶ˆíˆ¬ëª…í•œ ê²°ê³¼ëŠ” ì •ë¶€ ê¸°ê´€ì˜ ì˜ì‚¬ê²°ì •ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê°œì¸ì •ë³´ ë³´í˜¸ì™€ ì°¨ë³„ ë°©ì§€ì˜ ê· í˜•ì„ ì¬ê²€í† í•  í•„ìš”ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > [ì´ìŠˆ: issue] Artificial Intelligence and Privacy â€“ Issues and Challenges\n",
      "\n",
      "Further, those building the systems may unknowingly introduce their own human biases into the functionality. Because AI challenges the ability of information privacy to operate as it has done historically, the safeguard against...\n",
      "---\n",
      "\n",
      "**[5. TRANSPARENCY - Issue]**\n",
      "- **ì¶œì²˜:** https://www.trustpath.ai/blog/ai-transparency-what-it-is-and-why-it-matters-for-compliance (URL: N/A)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.2\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ íˆ¬ëª…ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì§€ì  ì¬ì‚° ë³´í˜¸ë¥¼ ê³ ë ¤í•´ì•¼ í•˜ë©°, ì˜ì‚¬ê²°ì • ê³¼ì •ê³¼ ë°ì´í„° ì‚¬ìš©ì„ ëª…í™•íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹œìŠ¤í…œì˜ ì„¸ë¶€ ê¸°ìˆ ì„ ê³µê°œí•  ê²½ìš° ë³´ì•ˆ ìœ„í—˜ì´ ì¦ê°€í•˜ê³ , ì•…ì˜ì ì¸ ì‚¬ìš©ìê°€ ì‹œìŠ¤í…œì„ ìš°íšŒí•  ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ìœ¤ë¦¬ì ì´ê³  ì•ˆì „í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ì„œëŠ” íˆ¬ëª…ì„±ê³¼ ë³´ì•ˆì„ ë™ì‹œì— ê³ ë ¤í•œ í”„ë ˆì„ì›Œí¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > [ì´ìŠˆ: issue] AI transparency: What it is and why it matters for compliance?\n",
      "\n",
      "To balance transparency in AI with IP protection, businesses should focus on communicating key insightsâ€”like how decisions are made or what data is usedâ€”without revealing the specific technical blueprints. This approach ensu...\n",
      "---\n",
      "\n",
      "**[6. TRANSPARENCY - Issue]**\n",
      "- **ì¶œì²˜:** https://www.trustpath.ai/blog/ai-transparency-what-it-is-and-why-it-matters-for-compliance (URL: N/A)\n",
      "- **ê°€ì¤‘ì¹˜:** 0.2\n",
      "- **í•µì‹¬ ìš”ì•½:** > AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ íˆ¬ëª…ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì§€ì  ì¬ì‚° ë³´í˜¸ë¥¼ ê³ ë ¤í•´ì•¼ í•˜ë©°, ê²°ì • ê³¼ì •ê³¼ ë°ì´í„° ì‚¬ìš©ì„ ëª…í™•íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ íˆ¬ëª…ì„±ì´ ë³´ì•ˆ ìœ„í—˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì•…ì˜ì ì¸ ì‚¬ìš©ìê°€ ì‹œìŠ¤í…œì„ ìš°íšŒí•  ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ìœ¤ë¦¬ì ì´ê³  ì•ˆì „í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ì„œëŠ” íˆ¬ëª…ì„±ê³¼ ë³´ì•ˆì„ ë™ì‹œì— ê³ ë ¤í•œ í”„ë ˆì„ì›Œí¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- **ì›ë¬¸ ì¼ë¶€:** > [ì´ìŠˆ: issue] AI transparency: What it is and why it matters for compliance?\n",
      "\n",
      "To balance transparency in AI with IP protection, businesses should focus on communicating key insightsâ€”like how decisions are made or what data is usedâ€”without revealing the specific technical blueprints. This approach ensu...\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ’» 3. ì „ì²´ ë°ì´í„° JSON í˜•ì‹ (Risk Assessor ìˆ˜ì‹  í˜•íƒœ)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\",\n",
      "  \"weights\": {\n",
      "    \"baseline\": 0.8,\n",
      "    \"issue\": 0.2\n",
      "  },\n",
      "  \"scores\": {\n",
      "    \"bias\": 1.0,\n",
      "    \"privacy\": 1.0,\n",
      "    \"transparency\": 1.0\n",
      "  },\n",
      "  \"baseline_sources\": [\n",
      "    {\n",
      "      \"category\": \"bias\",\n",
      "      \"document_type\": \"baseline\",\n",
      "      \"source\": \"UNESCO_Ethics_2021.pdf\",\n",
      "      \"chunk_info\": \"(í˜ì´ì§€ 40ì˜ ë‚´ìš©)\",\n",
      "      \"score\": 0.8,\n",
      "      \"summary\": \"AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ UNESCOì˜ ì •ì±… ê¶Œê³ ì‚¬í•­ì— ë”°ë¼ ìœ¤ë¦¬ì  ê¸°ì¤€ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ì´ë¥¼ ìœ„í•´ ê²½í—˜ ê³µìœ  ë©”ì»¤ë‹ˆì¦˜ê³¼ AI ê·œì œ ìƒŒë“œë°•ìŠ¤ê°€ í•„ìš”í•˜ë‹¤. ì´ëŸ¬í•œ ë„êµ¬ë“¤ì€ AI ê´€ë ¨ ì£¼ì²´ë“¤ì´ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì‹œìŠ¤í…œì˜ ì„¤ê³„ì™€ ìš´ì˜ì—ì„œ ìœ¤ë¦¬ì  ê³ ë ¤ê°€ í•„ìˆ˜ì ì´ë‹¤.\",\n",
      "      \"content_excerpt\": \"across UNESCOâ€™s areas of competence, an experience-\\nsharing mechanism, AI regulatory sandboxes, and an \\nassessment guide for all AI actors to evaluate their \\nadherence to policy recommendations mentioned in \\nthis document....\",\n",
      "      \"full_content\": \"across UNESCOâ€™s areas of competence, an experience-\\nsharing mechanism, AI regulatory sandboxes, and an \\nassessment guide for all AI actors to evaluate their \\nadherence to policy recommendations mentioned in \\nthis document.\"\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"bias\",\n",
      "      \"document_type\": \"baseline\",\n",
      "      \"source\": \"EU_AI_Act.pdf\",\n",
      "      \"chunk_info\": \"(í˜ì´ì§€ 14ì˜ ë‚´ìš©)\",\n",
      "      \"score\": 0.8,\n",
      "      \"summary\": \"AI ì„œë¹„ìŠ¤ ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì‹œì¥ì— ì¶œì‹œë˜ê¸° ì „ì— ìœ¤ë¦¬ì  í‰ê°€ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê³ , ì´ë¥¼ êµ­ê°€ ë‹¹êµ­ì— ì œê³µí•´ì•¼ í•˜ë©°, EU ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡í•´ì•¼ í•˜ëŠ” ì˜ë¬´ê°€ ìˆë‹¤. ì´ëŸ¬í•œ ê·œì •ì€ ì‹œìŠ¤í…œì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•˜ê³  íˆ¬ëª…ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤. ë”°ë¼ì„œ, í•´ë‹¹ ì‹œìŠ¤í…œì˜ ê°œë°œ ë° ìš´ì˜ ì‹œ ì² ì €í•œ ìœ¤ë¦¬ì  ê²€í† ê°€ í•„ìˆ˜ì ì´ë‹¤.\",\n",
      "      \"content_excerpt\": \"to above should draw up documentation of the assessment before that system is placed on the market or put into \\nservice and should provide that documentation to national competent authorities upon request. Such a provider \\nshould be obliged to register the AI system in the EU database established un...\",\n",
      "      \"full_content\": \"to above should draw up documentation of the assessment before that system is placed on the market or put into \\nservice and should provide that documentation to national competent authorities upon request. Suc\n",
      "...\n",
      "[ì „ì²´ JSON ë°ì´í„°ê°€ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë©ë‹ˆë‹¤.]\n"
     ]
    }
   ],
   "source": [
    "# evidence_collector.ipynbì˜ ë§ˆì§€ë§‰ ì…€ì— ì¶”ê°€í•˜ì—¬ ì‹¤í–‰\n",
    "\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# evidence_result ë³€ìˆ˜ê°€ collect_evidence(test_service_profile) ì‹¤í–‰ í›„ ì €ì¥ëœ ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "if 'evidence_result' in locals():\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # ğŸ“Š Risk Assessor ì „ë‹¬ ë°ì´í„° ìµœì¢… ì¶œë ¥ ë° í™•ì¸\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    display(Markdown(\"## ğŸš€ Risk Assessor ì—ì´ì „íŠ¸ ì „ë‹¬ ë‚´ìš© ìµœì¢… í™•ì¸\"))\n",
    "    \n",
    "    # 1. ë©”íƒ€ ì •ë³´ ì¶œë ¥\n",
    "    print(f\"ì„œë¹„ìŠ¤ëª…: {evidence_result['query']}\")\n",
    "    print(f\"ê°€ì¤‘ì¹˜: Baseline {evidence_result['weights']['baseline']} : Issue {evidence_result['weights']['issue']}\")\n",
    "    print(f\"ìˆ˜ì§‘ëœ ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: {list(evidence_result['scores'].keys())}\")\n",
    "    print(f\"ì´ ì „ë‹¬ ì¦ê±° ê°œìˆ˜: {len(evidence_result['baseline_sources']) + len(evidence_result['issue_sources'])}ê°œ\\n\")\n",
    "\n",
    "    # 2. Baseline ì¦ê±° ìƒì„¸ ì¶œë ¥\n",
    "    display(Markdown(\"### ğŸ“š 1. Baseline ì¦ê±° (ë²•ì /ìœ¤ë¦¬ ê¸°ì¤€ ê·¼ê±°)\"))\n",
    "    if evidence_result['baseline_sources']:\n",
    "        for i, src in enumerate(evidence_result['baseline_sources']):\n",
    "            category = src['category'].upper()\n",
    "            \n",
    "            # Risk Assessorê°€ ê°€ì¥ ë¨¼ì € ë³´ê²Œ ë  í•µì‹¬ ì •ë³´ ì¶œë ¥\n",
    "            output = f\"\"\"\n",
    "**[{i+1}. {category} - Baseline]**\n",
    "- **ì¶œì²˜:** {src['source']} {src['chunk_info']}\n",
    "- **ê°€ì¤‘ì¹˜:** {src['score']:.1f}\n",
    "- **í•µì‹¬ ìš”ì•½:** > {src['summary']}\n",
    "- **ì›ë¬¸ ì¼ë¶€:** > {src['content_excerpt']}\n",
    "---\"\"\"\n",
    "            print(output)\n",
    "    else:\n",
    "        print(\"ìˆ˜ì§‘ëœ Baseline ì¦ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. Issue ì¦ê±° ìƒì„¸ ì¶œë ¥\n",
    "    display(Markdown(\"### ğŸ“° 2. Issue ì¦ê±° (ìµœì‹  ì‚¬íšŒì  ë°˜ì‘ ê·¼ê±°)\"))\n",
    "    if evidence_result['issue_sources']:\n",
    "        for i, src in enumerate(evidence_result['issue_sources']):\n",
    "            category = src['category'].upper()\n",
    "            \n",
    "            # Risk Assessorê°€ ê°€ì¥ ë¨¼ì € ë³´ê²Œ ë  í•µì‹¬ ì •ë³´ ì¶œë ¥\n",
    "            output = f\"\"\"\n",
    "**[{i+1}. {category} - Issue]**\n",
    "- **ì¶œì²˜:** {src['source']} (URL: {src.get('url', 'N/A')})\n",
    "- **ê°€ì¤‘ì¹˜:** {src['score']:.1f}\n",
    "- **í•µì‹¬ ìš”ì•½:** > {src['summary']}\n",
    "- **ì›ë¬¸ ì¼ë¶€:** > {src['content_excerpt']}\n",
    "---\"\"\"\n",
    "            print(output)\n",
    "    else:\n",
    "        print(\"ìˆ˜ì§‘ëœ Issue ì¦ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 4. ì „ì²´ ë°ì´í„° JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (Risk Assessorê°€ ì½”ë“œë¡œ ë°›ëŠ” í˜•íƒœ)\n",
    "    display(Markdown(\"### ğŸ’» 3. ì „ì²´ ë°ì´í„° JSON í˜•ì‹ (Risk Assessor ìˆ˜ì‹  í˜•íƒœ)\"))\n",
    "    # ì „ì²´ ë”•ì…”ë„ˆë¦¬ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥\n",
    "    # (ì£¼ì˜: ë‚´ìš©ì´ ë§¤ìš° ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ì¼ë¶€ë§Œ ì¶œë ¥í•  ìˆ˜ ìˆìŒ)\n",
    "    full_json_output = json.dumps(evidence_result, indent=2, ensure_ascii=False)\n",
    "    print(full_json_output[:2000] + \"\\n...\\n[ì „ì²´ JSON ë°ì´í„°ê°€ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë©ë‹ˆë‹¤.]\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ 'evidence_result' ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'step8. í…ŒìŠ¤íŠ¸ ì‹¤í–‰'ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-JIaWGMA_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fe3d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "\n",
    "# 👩‍💻 Author    : Hyelim Jo\n",
    "# 🎯 Purpose   : AI 윤리성 리스크 진단 에이전트 v1.0\n",
    "# 📅 Created   : 2025-10-22\n",
    "# 📜 Note      : evidence_collector.ipynb\n",
    "\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17d45862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- Update Log ----------------------------------\n",
    "\n",
    "# 2025-10-22 16:00 / 초기 생성 / Evidence Collector 기본 구조 구현\n",
    "# 2025-10-22 16:30 / RAG 메모리 설계 / Baseline + Issue 메모리 분리\n",
    "# 2025-10-22 17:00 / HuggingFace 임베딩 적용 / 경제성 개선\n",
    "# 2025-10-23 09:00 / 웹 크롤링 실제 구현 / Tavily Search API를 사용하여 최신 뉴스/논문 수집\n",
    "# 2025-10-23 09:30 / Baseline 쿼리 강화 / EU, OECD, UNESCO 기준 명시 및 파일 구성에 맞춰 로드 로직 명확화\n",
    "# 2025-10-23 11:00 / 평가 로직 구현 / LLM 기반의 위험도(High/Limited/Minimal) 평가\n",
    "# 2025-10-23 11:30 / JSON 출력 포맷 정의 / Mitigation Recommender에게 전달할 구조 확정\n",
    "\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23ef9c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 불러오기 완료!\n"
     ]
    }
   ],
   "source": [
    "# step1. 라이브러리 불러오기\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI # LLM 사용을 위해 필요\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 라이브러리 불러오기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22844965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2. 설정 및 경로 정의\n",
    "# 데이터 경로 설정 (agents 폴더 내에서 실행 가정)\n",
    "base_dir = os.path.join(\"..\", \"data\")\n",
    "reference_dir = os.path.join(base_dir, \"reference\")\n",
    "crawled_dir = os.path.join(base_dir, \"crawled\")\n",
    "processed_dir = os.path.join(base_dir, \"processed\")\n",
    "baseline_embed_dir = os.path.join(base_dir, \"embeddings\", \"baseline\")\n",
    "issue_embed_dir = os.path.join(base_dir, \"embeddings\", \"issue\")\n",
    "\n",
    "# 디렉토리 생성\n",
    "for dir_path in [crawled_dir, processed_dir, baseline_embed_dir, issue_embed_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "decd4add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKAX\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-JIaWGMA_-py3.11\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChatOpenAI LLM 초기화 완료!\n",
      "✅ HuggingFace 임베딩 모델 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "# step3. 임베딩 모델 및 LLM 초기화\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "# 💡 LLM 초기화 (요약 및 평가에 사용)\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    print(\"✅ ChatOpenAI LLM 초기화 완료!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ ChatOpenAI 초기화 실패: {e}\")\n",
    "    llm = None\n",
    "\n",
    "print(\"✅ HuggingFace 임베딩 모델 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ad70088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline 메모리 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step4. Baseline 메모리 구축 (EU, OECD, UNESCO 문서)\n",
    "def build_baseline_memory():\n",
    "    \"\"\"공식 문서 기반 Baseline 메모리 구축\"\"\"\n",
    "    baseline_docs = []\n",
    "    \n",
    "    # PDF 파일 로드\n",
    "    pdf_files = [\n",
    "        \"EU_AI_Act.pdf\",\n",
    "        \"OECD_Privacy_2024.pdf\", \n",
    "        \"UNESCO_Ethics_2021.pdf\"\n",
    "    ]\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(reference_dir, pdf_file)\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            loader = PyMuPDFLoader(pdf_path)\n",
    "            docs = loader.load()\n",
    "            print(f\"✅ {pdf_file} 로드 완료\")\n",
    "            \n",
    "            # 메타데이터에 문서 타입 추가 및 페이지 번호 정보 포함\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"document_type\"] = \"baseline\"\n",
    "                doc.metadata[\"source\"] = pdf_file\n",
    "                doc.metadata[\"page\"] = doc.metadata.get(\"page\", 0) + 1 # 페이지 번호는 1부터 시작\n",
    "            baseline_docs.extend(docs)\n",
    "        else:\n",
    "            print(f\"⚠️ {pdf_file} 파일이 지정된 경로에 없습니다: {pdf_path}\")\n",
    "    \n",
    "    if not baseline_docs:\n",
    "        print(\"❌ Baseline 문서를 로드하지 못했습니다. RAG가 Baseline 증거를 찾지 못할 수 있습니다.\")\n",
    "        split_docs = [Document(page_content=\"No official baseline documents loaded.\", metadata={\"source\": \"N/A\", \"document_type\": \"baseline\", \"page\": 0})]\n",
    "    else:\n",
    "        # 텍스트 분할\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        split_docs = text_splitter.split_documents(baseline_docs)\n",
    "    \n",
    "    # ChromaDB에 저장\n",
    "    baseline_vectorstore = Chroma.from_documents(\n",
    "        documents=split_docs,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=baseline_embed_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Baseline 메모리 구축 완료 ({len(split_docs)}개 청크)\")\n",
    "    return baseline_vectorstore\n",
    "\n",
    "print(\"✅ Baseline 메모리 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c485a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 웹 크롤링 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step5. 웹 크롤링 함수 정의 (Tavily 사용)\n",
    "def crawl_web_content(keywords: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Tavily를 사용하여 웹에서 최신 AI 윤리 이슈 관련 기사 크롤링\"\"\"\n",
    "    tavily = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))\n",
    "    crawled_data = []\n",
    "    search_queries = []\n",
    "    for keyword in keywords:\n",
    "        search_queries.extend([\n",
    "            f\"AI {keyword} 윤리 이슈\",\n",
    "            f\"AI {keyword} 편향성 문제\",\n",
    "            f\"AI {keyword} 개인정보보호\",\n",
    "        ])\n",
    "    unique_queries = list(set(search_queries))[:5] # 최대 5개의 고유 쿼리로 제한\n",
    "    \n",
    "    for query in unique_queries:\n",
    "        print(f\"     - Tavily 검색 중: {query}...\")\n",
    "        try:\n",
    "            results = tavily.search(\n",
    "                query=query, \n",
    "                search_depth=\"advanced\", \n",
    "                max_results=5, \n",
    "                include_raw_content=True\n",
    "            )\n",
    "            for result in results.get(\"results\", []):\n",
    "                if result.get(\"content\"):\n",
    "                    crawled_data.append({\n",
    "                        \"title\": result.get(\"title\", \"No Title\"),\n",
    "                        \"content\": result[\"content\"],\n",
    "                        \"source\": result.get(\"url\", \"Unknown Source\"),\n",
    "                        \"url\": result.get(\"url\", \"\"),\n",
    "                        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                        \"category\": \"issue\"\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Tavily 검색 실패 ({query}): {e}\")\n",
    "            continue\n",
    "\n",
    "    # 필터링 로직 (300자 이상, 선정적 표현 제거, 중복 URL 제거)\n",
    "    filtered_data = []\n",
    "    seen_urls = set()\n",
    "    for item in crawled_data:\n",
    "        if len(item[\"content\"]) >= 300:\n",
    "            if not any(word in item[\"content\"].lower() for word in [\"충격\", \"폭로\", \"clickbait\", \"논란의\", \"대박\"]):\n",
    "                if item[\"url\"] not in seen_urls:\n",
    "                    filtered_data.append(item)\n",
    "                    seen_urls.add(item[\"url\"])\n",
    "\n",
    "    print(f\"✅ 웹 크롤링 완료 ({len(filtered_data)}개 문서)\")\n",
    "    return filtered_data\n",
    "\n",
    "print(\"✅ 웹 크롤링 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e403121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Issue 메모리 구축 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step6. Issue 메모리 구축 (웹 크롤링 결과를 RAG에 저장)\n",
    "def build_issue_memory(keywords: List[str]):\n",
    "    \"\"\"웹 크롤링 결과 기반 Issue 메모리 (Vectorstore) 구축\"\"\"\n",
    "    crawled_data = crawl_web_content(keywords)\n",
    "    issue_docs = []\n",
    "    \n",
    "    for item in crawled_data:\n",
    "        doc = Document(\n",
    "            page_content=f\"[이슈: {item['category']}] {item['title']}\\n\\n{item['content']}\",\n",
    "            metadata={\n",
    "                \"document_type\": \"issue\",\n",
    "                \"source\": item[\"source\"],\n",
    "                \"url\": item[\"url\"],\n",
    "                \"date\": item[\"date\"],\n",
    "                \"category\": item[\"category\"], # 임시로 'issue'로 설정\n",
    "                \"title\": item[\"title\"]\n",
    "            }\n",
    "        )\n",
    "        issue_docs.append(doc)\n",
    "    \n",
    "    if issue_docs:\n",
    "        # Issue 문서는 ChromaDB에 저장\n",
    "        issue_vectorstore = Chroma.from_documents(\n",
    "            documents=issue_docs,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=issue_embed_dir\n",
    "        )\n",
    "        print(f\"✅ Issue 메모리 구축 완료 ({len(issue_docs)}개 문서)\")\n",
    "        return issue_vectorstore\n",
    "    else:\n",
    "        print(\"⚠️ 크롤링된 데이터가 없습니다.\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Issue 메모리 구축 함수 정의 완료\")\n",
    "\n",
    "\n",
    "# 💡 신규 함수 정의: LLM을 이용한 증거 요약\n",
    "def summarize_evidence_with_llm(docs: List[Document], query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"검색된 Document 목록을 LLM을 사용하여 요약하고 세부 정보와 결합합니다.\"\"\"\n",
    "    if not llm:\n",
    "        print(\"⚠️ LLM이 초기화되지 않아 요약을 건너뜁니다.\")\n",
    "        return []\n",
    "\n",
    "    summarized_results = []\n",
    "    \n",
    "    summary_prompt_template = \"\"\"당신은 AI 윤리 리스크 진단 전문가입니다. 다음 정보를 분석하여 한국어로 3줄 이내의 간결하고 핵심적인 요약을 제공하세요.\n",
    "    이 요약은 'AI 서비스 {query}의 윤리 리스크'에 대한 근거로 사용될 것입니다.\n",
    "    ---\n",
    "    문서 출처: {source} ({document_type}) {chunk_info}\n",
    "    문서 내용: {content}\n",
    "    ---\n",
    "    요약:\"\"\"\n",
    "    summary_prompt = PromptTemplate(template=summary_prompt_template, input_variables=[\"query\", \"source\", \"document_type\", \"content\", \"chunk_info\"])\n",
    "\n",
    "    for doc in docs:\n",
    "        content = doc.page_content\n",
    "        source = doc.metadata.get(\"source\", doc.metadata.get(\"url\", \"Unknown\"))\n",
    "        doc_type = doc.metadata.get(\"document_type\", \"Unknown\")\n",
    "        category = doc.metadata.get(\"category\", \"N/A\")\n",
    "\n",
    "        # 문서 타입에 따른 청크 정보 설정\n",
    "        if doc_type == \"baseline\":\n",
    "            chunk_info = f\"(페이지 {doc.metadata.get('page', 'N/A')}의 내용)\"\n",
    "            score = 0.8 # Baseline 가중치\n",
    "        else: # issue\n",
    "            chunk_info = \"(웹 기사 원문)\"\n",
    "            score = 0.2 # Issue 가중치\n",
    "\n",
    "        # 프롬프트 구성 및 요약 생성\n",
    "        prompt_value = summary_prompt.invoke({\n",
    "            \"query\": query,\n",
    "            \"source\": source,\n",
    "            \"document_type\": doc_type,\n",
    "            \"content\": content,\n",
    "            \"chunk_info\": chunk_info\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # LLM 호출\n",
    "            summary_response = llm.invoke(prompt_value.to_string())\n",
    "            summary = summary_response.content.strip()\n",
    "        except Exception as e:\n",
    "            summary = f\"LLM 요약 실패. Error: {e}\"\n",
    "        \n",
    "        # Risk Assessor 에이전트에 전달할 상세 구조\n",
    "        summarized_results.append({\n",
    "            \"category\": category,\n",
    "            \"document_type\": doc_type,\n",
    "            \"source\": source,\n",
    "            \"chunk_info\": chunk_info, # PDF 페이지 또는 웹 기사 여부\n",
    "            \"score\": score,\n",
    "            \"summary\": summary, \n",
    "            \"content_excerpt\": content[:300] + \"...\", # 원문 내용의 일부 (너무 길어지지 않도록)\n",
    "            \"full_content\": content # Risk Assessor에서 필요할 경우를 대비하여 전체 원문도 전달\n",
    "        })\n",
    "        \n",
    "    return summarized_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a131f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 증거 수집 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# step7. 증거 수집 함수 정의 (가중치 8:2 적용)\n",
    "def collect_evidence(service_profile: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    서비스 프로파일 기반 증거 수집 (Baseline 0.8 : Issue 0.2)\n",
    "    - Risk Assessor에게 전달할 증거 소스 목록 및 가중치 점수, 요약 포함\n",
    "    \"\"\"\n",
    "    \n",
    "    service_name = service_profile.get(\"service_name\", \"\")\n",
    "    # 💡 Service Profiler에서 변경된 키를 사용하도록 수정\n",
    "    risk_categories = service_profile.get(\"diagnosed_risk_categories\", []) \n",
    "    service_type = service_profile.get(\"service_type\", \"\")\n",
    "    \n",
    "    print(f\"\\n🔍 증거 수집 시작: {service_name}\")\n",
    "    \n",
    "    # 메모리 구축\n",
    "    baseline_vectorstore = build_baseline_memory()\n",
    "    issue_vectorstore = build_issue_memory(risk_categories)\n",
    "    \n",
    "    evidence_results = {\n",
    "        \"query\": service_name,\n",
    "        \"weights\": {\"baseline\": 0.8, \"issue\": 0.2},\n",
    "        \"scores\": {},\n",
    "        \"baseline_sources\": [],\n",
    "        \"issue_sources\": []\n",
    "    }\n",
    "    \n",
    "    all_docs_to_summarize = []\n",
    "    \n",
    "    # 1. 각 리스크 카테고리별 증거 검색\n",
    "    for category in risk_categories:\n",
    "        \n",
    "        # Baseline 검색 쿼리 강화\n",
    "        baseline_query = f\"{service_name} {category} 리스크 {service_type} (EU AI Act, OECD, UNESCO 윤리 기준)\"\n",
    "        issue_query = f\"최신 뉴스 논문 AI {service_name} {category} 문제\"\n",
    "        \n",
    "        print(f\"\\n     📊 {category.upper()} 리스크 검색 중...\")\n",
    "        \n",
    "        # Baseline 검색\n",
    "        baseline_docs = baseline_vectorstore.similarity_search(baseline_query, k=3)\n",
    "        \n",
    "        # Issue 검색\n",
    "        issue_docs = []\n",
    "        if issue_vectorstore:\n",
    "            issue_docs = issue_vectorstore.similarity_search(issue_query, k=2)\n",
    "            \n",
    "        # 검색된 문서를 요약 대상 리스트에 추가 (카테고리 메타데이터 부여)\n",
    "        for doc in baseline_docs:\n",
    "            doc.metadata['category'] = category\n",
    "            all_docs_to_summarize.append(doc)\n",
    "        for doc in issue_docs:\n",
    "            doc.metadata['category'] = category\n",
    "            all_docs_to_summarize.append(doc)\n",
    "            \n",
    "        # 종합 점수 계산 (참고용)\n",
    "        baseline_weight = 0.8\n",
    "        issue_weight = 0.2 if issue_docs else 0.0\n",
    "        total_score = (len(baseline_docs) > 0) * baseline_weight + (len(issue_docs) > 0) * issue_weight\n",
    "        evidence_results[\"scores\"][category] = total_score\n",
    "        \n",
    "        print(f\" - 검색된 Baseline 청크: {len(baseline_docs)}개\")\n",
    "        print(f\" - 검색된 Issue 문서: {len(issue_docs)}개\")\n",
    "\n",
    "    print(\"\\n📝 검색된 증거들을 LLM을 사용하여 요약 중...\")\n",
    "    \n",
    "    # 2. 통합 요약 및 데이터 구조화\n",
    "    summarized_evidences = summarize_evidence_with_llm(all_docs_to_summarize, service_name)\n",
    "    \n",
    "    # 3. 최종 결과 리스트에 추가\n",
    "    for evidence in summarized_evidences:\n",
    "        if evidence['document_type'] == 'baseline':\n",
    "            evidence_results[\"baseline_sources\"].append(evidence)\n",
    "        elif evidence['document_type'] == 'issue':\n",
    "            evidence_results[\"issue_sources\"].append(evidence)\n",
    "    \n",
    "    print(f\"\\n✅ 증거 수집 및 요약 완료!\")\n",
    "    return evidence_results\n",
    "\n",
    "print(\"✅ 증거 수집 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a4c0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔍 Evidence Collector 시작...\n",
      "============================================================\n",
      "\n",
      "📝 분석할 서비스: 채용 지원자의 이력서를 AI로 분석하여 적합한 후보자를 추천하는 시스템입니다....\n",
      "\n",
      "🔍 증거 수집 시작: 이력서 분석 추천 시스템\n",
      "✅ EU_AI_Act.pdf 로드 완료\n",
      "✅ OECD_Privacy_2024.pdf 로드 완료\n",
      "✅ UNESCO_Ethics_2021.pdf 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline 메모리 구축 완료 (2075개 청크)\n",
      "     - Tavily 검색 중: AI bias 편향성 문제...\n",
      "     - Tavily 검색 중: AI privacy 편향성 문제...\n",
      "     - Tavily 검색 중: AI transparency 개인정보보호...\n",
      "     - Tavily 검색 중: AI privacy 윤리 이슈...\n",
      "     - Tavily 검색 중: AI bias 윤리 이슈...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 웹 크롤링 완료 (21개 문서)\n",
      "✅ Issue 메모리 구축 완료 (21개 문서)\n",
      "\n",
      "     📊 BIAS 리스크 검색 중...\n",
      " - 검색된 Baseline 청크: 3개\n",
      " - 검색된 Issue 문서: 2개\n",
      "\n",
      "     📊 PRIVACY 리스크 검색 중...\n",
      " - 검색된 Baseline 청크: 3개\n",
      " - 검색된 Issue 문서: 2개\n",
      "\n",
      "     📊 TRANSPARENCY 리스크 검색 중...\n",
      " - 검색된 Baseline 청크: 3개\n",
      " - 검색된 Issue 문서: 2개\n",
      "\n",
      "📝 검색된 증거들을 LLM을 사용하여 요약 중...\n",
      "\n",
      "✅ 증거 수집 및 요약 완료!\n",
      "\n",
      "============================================================\n",
      "📊 증거 수집 결과 요약 및 다음 에이전트 전달 내용\n",
      "============================================================\n",
      "  - 서비스명: 이력서 분석 추천 시스템\n",
      "  - 가중치: Baseline 0.8 : Issue 0.2\n",
      "  - 수집된 리스크 카테고리: ['bias', 'privacy', 'transparency']\n",
      "\n",
      "------------------------------------------------------------\n",
      "🚨 Risk Assessor에 전달되는 데이터 구조 요약 (첫 번째 증거 예시)\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Baseline 근거 예시]\n",
      "  - 리스크 카테고리: BIAS\n",
      "  - 출처: UNESCO_Ethics_2021.pdf (페이지 40의 내용)\n",
      "  - **요약 (핵심 근거):** AI 서비스 이력서 분석 추천 시스템은 UNESCO의 정책 권고사항에 따라 윤리적 기준을 준수해야 하며, 이를 위해 경험 공유 메커니즘과 AI 규제 샌드박스가 필요하다. 이러한 도구들은 AI 관련 주체들이 윤리 리스크를 평가하고 관리하는 데 도움을 줄 수 있다. 따라서 시스템의 설계와 운영에서 윤리적 고려가 필수적이다.\n",
      "  - 원문 내용 (일부): across UNESCO’s areas of competence, an experience-\n",
      "sharing mechanism, AI regulatory sandboxes, and an \n",
      "assessment guide for all AI actors to evaluate their \n",
      "adherence to policy recommendations mentioned in \n",
      "this document....\n",
      "\n",
      "[Issue 근거 예시]\n",
      "  - 리스크 카테고리: BIAS\n",
      "  - 출처: https://m.blog.naver.com/edawoon/221835492705 (N/A) (웹 기사 원문)\n",
      "  - **요약 (사회적 반응):** AI 서비스 이력서 분석 추천 시스템은 알고리즘의 편향성 문제로 인해 불공정한 결정이 내려질 위험이 있다. 인공지능이 사람의 편견을 줄일 수 있는 잠재력이 있지만, 여전히 인간의 판단이 필요하며, 사회적 맥락과 데이터 수집 방법의 문제를 고려해야 한다. 따라서 공정성을 확보하기 위한 신중한 접근이 필수적이다.\n",
      "  - 원문 내용 (일부): [이슈: issue] [맥킨지 보고서] 인공지능의 편향성(bias)을 해결하기 위한 방법\n",
      "\n",
      "MGI-Tackling-bias-in-AI-June-2019.pdf\n",
      "\n",
      "파일 다운로드\n",
      "\n",
      "<인공지능 경계선: 인공지능 및 사람들의 편견(Notes from the AI frontier: Tackling bias in AI (and in humans))>에서는 알고리즘이 사람들의 편견으로 발생한 불공정한 차이를 줄이는 데 도움을 줄 수 있는 곳과 인공지능으로 인해 확장될 수 있는 불공정한 편견을 비판적으로 분석하기 위한 개요를 보여준다.\n",
      "\n",
      "​\n",
      "\n",
      "​...\n",
      "\n",
      "------------------------------------------------------------\n",
      "🔗 최종적으로 15개의 상세 증거가 Risk Assessor로 전달됩니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# step8. 테스트 실행\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔍 Evidence Collector 시작...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 💡 Service Profiler에서 받은 결과 (예시, 변경된 키 반영)\n",
    "test_service_profile = {\n",
    "    \"service_name\": \"이력서 분석 추천 시스템\",\n",
    "    \"service_type\": \"recruitment system\", \n",
    "    \"description\": \"채용 지원자의 이력서를 AI로 분석하여 적합한 후보자를 추천하는 시스템입니다.\",\n",
    "    \"diagnosed_risk_categories\": [\"bias\", \"privacy\", \"transparency\"] # 변경된 키\n",
    "}\n",
    "\n",
    "print(f\"\\n📝 분석할 서비스: {test_service_profile['description']}...\")\n",
    "\n",
    "# 증거 수집 실행\n",
    "evidence_result = collect_evidence(test_service_profile)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 증거 수집 결과 요약 및 다음 에이전트 전달 내용\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  - 서비스명: {evidence_result['query']}\")\n",
    "print(f\"  - 가중치: Baseline {evidence_result['weights']['baseline']} : Issue {evidence_result['weights']['issue']}\")\n",
    "print(f\"  - 수집된 리스크 카테고리: {list(evidence_result['scores'].keys())}\")\n",
    "\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(\"🚨 Risk Assessor에 전달되는 데이터 구조 요약 (첫 번째 증거 예시)\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# 전달될 데이터 구조 예시 출력 (첫 번째 Baseline 소스와 첫 번째 Issue 소스)\n",
    "if evidence_result['baseline_sources']:\n",
    "    b_src = evidence_result['baseline_sources'][0]\n",
    "    print(\"\\n[Baseline 근거 예시]\")\n",
    "    print(f\"  - 리스크 카테고리: {b_src['category'].upper()}\")\n",
    "    print(f\"  - 출처: {b_src['source']} {b_src['chunk_info']}\")\n",
    "    print(f\"  - **요약 (핵심 근거):** {b_src['summary']}\")\n",
    "    print(f\"  - 원문 내용 (일부): {b_src['content_excerpt']}\")\n",
    "\n",
    "if evidence_result['issue_sources']:\n",
    "    i_src = evidence_result['issue_sources'][0]\n",
    "    print(\"\\n[Issue 근거 예시]\")\n",
    "    print(f\"  - 리스크 카테고리: {i_src['category'].upper()}\")\n",
    "    print(f\"  - 출처: {i_src['source']} ({i_src.get('url', 'N/A')}) {i_src['chunk_info']}\")\n",
    "    print(f\"  - **요약 (사회적 반응):** {i_src['summary']}\")\n",
    "    print(f\"  - 원문 내용 (일부): {i_src['content_excerpt']}\")\n",
    "\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(f\"🔗 최종적으로 {len(evidence_result['baseline_sources']) + len(evidence_result['issue_sources'])}개의 상세 증거가 Risk Assessor로 전달됩니다.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff60b438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 🚀 Risk Assessor 에이전트 전달 내용 최종 확인"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서비스명: 이력서 분석 추천 시스템\n",
      "가중치: Baseline 0.8 : Issue 0.2\n",
      "수집된 리스크 카테고리: ['bias', 'privacy', 'transparency']\n",
      "총 전달 증거 개수: 15개\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 📚 1. Baseline 증거 (법적/윤리 기준 근거)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**[1. BIAS - Baseline]**\n",
      "- **출처:** UNESCO_Ethics_2021.pdf (페이지 40의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 UNESCO의 정책 권고사항에 따라 윤리적 기준을 준수해야 하며, 이를 위해 경험 공유 메커니즘과 AI 규제 샌드박스가 필요하다. 이러한 도구들은 AI 관련 주체들이 윤리 리스크를 평가하고 관리하는 데 도움을 줄 수 있다. 따라서 시스템의 설계와 운영에서 윤리적 고려가 필수적이다.\n",
      "- **원문 일부:** > across UNESCO’s areas of competence, an experience-\n",
      "sharing mechanism, AI regulatory sandboxes, and an \n",
      "assessment guide for all AI actors to evaluate their \n",
      "adherence to policy recommendations mentioned in \n",
      "this document....\n",
      "---\n",
      "\n",
      "**[2. BIAS - Baseline]**\n",
      "- **출처:** EU_AI_Act.pdf (페이지 14의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 시장에 출시되기 전에 윤리적 평가 문서를 작성하고, 이를 국가 당국에 제공해야 하며, EU 데이터베이스에 등록해야 하는 의무가 있다. 이러한 규정은 시스템의 윤리적 리스크를 관리하고 투명성을 확보하기 위한 것이다. 따라서, 해당 시스템의 개발 및 운영 시 철저한 윤리적 검토가 필수적이다.\n",
      "- **원문 일부:** > to above should draw up documentation of the assessment before that system is placed on the market or put into \n",
      "service and should provide that documentation to national competent authorities upon request. Such a provider \n",
      "should be obliged to register the AI system in the EU database established un...\n",
      "---\n",
      "\n",
      "**[3. BIAS - Baseline]**\n",
      "- **출처:** EU_AI_Act.pdf (페이지 15의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 시장에 출시되기 전에 윤리적 평가 문서를 작성하고, 요청 시 국가 당국에 제출해야 한다. 또한, 해당 시스템은 EU 규정에 따라 데이터베이스에 등록해야 하며, 이는 윤리적 리스크 관리의 필수 조건이다. 이러한 절차는 시스템의 투명성과 책임성을 높이는 데 기여한다.\n",
      "- **원문 일부:** > to above should draw up documentation of the assessment before that system is placed on the market or put into \n",
      "service and should provide that documentation to national competent authorities upon request. Such a provider \n",
      "should be obliged to register the AI system in the EU database established un...\n",
      "---\n",
      "\n",
      "**[4. PRIVACY - Baseline]**\n",
      "- **출처:** OECD_Privacy_2024.pdf (페이지 40의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > OECD의 개인정보 보호 가이드라인은 AI에 특화되지 않은 프라이버시 리스크 관리 프레임워크를 제시하며, AI와 프라이버시 간의 연계를 위한 추가 작업이 필요하다고 강조한다. 이러한 접근은 AI 서비스 이력서 분석 추천 시스템의 윤리적 리스크를 평가하는 데 중요한 기초가 될 수 있다. AI 생애 주기 프레임워크를 통합함으로써 보다 포괄적인 리스크 관리가 가능해진다.\n",
      "- **원문 일부:** > the OECD Privacy Guidelines, and presents a framework for privacy risk management which is not AI-\n",
      "specific, in keeping with the approach of the Guidelines (OECD, 2023[44]). Further work bridging AI and \n",
      "privacy works could incorporate the AI lifecycle framework presented in OECD reports (OECD, 2022...\n",
      "---\n",
      "\n",
      "**[5. PRIVACY - Baseline]**\n",
      "- **출처:** OECD_Privacy_2024.pdf (페이지 41의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > OECD의 개인정보 보호 가이드라인은 AI에 특화되지 않은 프라이버시 리스크 관리 프레임워크를 제시하며, AI와 프라이버시 간의 연계를 위한 추가 작업이 필요하다고 강조한다. 이러한 접근은 AI 서비스 이력서 분석 추천 시스템에서 발생할 수 있는 윤리적 리스크를 관리하는 데 중요한 기초가 된다. 따라서, AI 생애 주기 프레임워크를 통합하는 것이 필수적이다.\n",
      "- **원문 일부:** > the OECD Privacy Guidelines, and presents a framework for privacy risk management which is not AI-\n",
      "specific, in keeping with the approach of the Guidelines (OECD, 2023[44]). Further work bridging AI and \n",
      "privacy works could incorporate the AI lifecycle framework presented in OECD reports (OECD, 2022...\n",
      "---\n",
      "\n",
      "**[6. PRIVACY - Baseline]**\n",
      "- **출처:** OECD_Privacy_2024.pdf (페이지 41의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 OECD의 개인정보 보호 가이드라인에 따라 AI와 개인정보 보호 간의 연계를 고려해야 하며, AI 생애 주기 프레임워크를 통합하여 윤리적 리스크를 관리해야 한다. 이러한 접근은 AI 관련 법률 및 규제, 예를 들어 EU AI 법안과도 일치한다. 따라서, 시스템 설계 시 윤리적 고려가 필수적이다.\n",
      "- **원문 일부:** > the OECD Privacy Guidelines, and presents a framework for privacy risk management which is not AI-\n",
      "specific, in keeping with the approach of the Guidelines (OECD, 2023[44]). Further work bridging AI and \n",
      "privacy works could incorporate the AI lifecycle framework presented in OECD reports (OECD, 2022...\n",
      "---\n",
      "\n",
      "**[7. TRANSPARENCY - Baseline]**\n",
      "- **출처:** EU_AI_Act.pdf (페이지 82의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 인공지능의 투명성 의무를 준수해야 하며, 인위적으로 생성되거나 조작된 콘텐츠의 탐지 및 라벨링에 대한 실천 강령을 마련해야 한다. 이러한 의무를 이행하지 않을 경우 윤리적 리스크가 발생할 수 있다. 따라서, 관련 법규를 준수하는 것이 필수적이다.\n",
      "- **원문 일부:** > prejudice to other transparency obligations laid down in Union or national law for deployers of AI systems.\n",
      "7.\n",
      "The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level to facilitate the effective \n",
      "implementation of the obligations regarding the detection and la...\n",
      "---\n",
      "\n",
      "**[8. TRANSPARENCY - Baseline]**\n",
      "- **출처:** EU_AI_Act.pdf (페이지 83의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 인공지능의 투명성 의무를 준수해야 하며, 인위적으로 생성되거나 조작된 콘텐츠의 탐지 및 라벨링에 대한 실천 강령을 마련해야 한다. 이러한 의무를 이행하지 않을 경우 윤리적 리스크가 발생할 수 있다. 따라서, 관련 법규를 준수하는 것이 필수적이다.\n",
      "- **원문 일부:** > prejudice to other transparency obligations laid down in Union or national law for deployers of AI systems.\n",
      "7.\n",
      "The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level to facilitate the effective \n",
      "implementation of the obligations regarding the detection and la...\n",
      "---\n",
      "\n",
      "**[9. TRANSPARENCY - Baseline]**\n",
      "- **출처:** EU_AI_Act.pdf (페이지 83의 내용)\n",
      "- **가중치:** 0.8\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 인공지능의 투명성 의무를 준수해야 하며, 인위적으로 생성되거나 조작된 콘텐츠의 탐지 및 라벨링에 대한 실효성 있는 실행을 위한 행동 강령이 필요하다. 이러한 윤리적 리스크는 법적 요구사항을 충족하지 못할 경우 발생할 수 있다. 따라서, 시스템의 설계와 운영에서 투명성을 확보하는 것이 중요하다.\n",
      "- **원문 일부:** > prejudice to other transparency obligations laid down in Union or national law for deployers of AI systems.\n",
      "7.\n",
      "The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level to facilitate the effective \n",
      "implementation of the obligations regarding the detection and la...\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 📰 2. Issue 증거 (최신 사회적 반응 근거)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**[1. BIAS - Issue]**\n",
      "- **출처:** https://m.blog.naver.com/edawoon/221835492705 (URL: N/A)\n",
      "- **가중치:** 0.2\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 알고리즘의 편향성 문제로 인해 불공정한 결정이 내려질 위험이 있다. 인공지능이 사람의 편견을 줄일 수 있는 잠재력이 있지만, 여전히 인간의 판단이 필요하며, 사회적 맥락과 데이터 수집 방법의 문제를 고려해야 한다. 따라서 공정성을 확보하기 위한 신중한 접근이 필수적이다.\n",
      "- **원문 일부:** > [이슈: issue] [맥킨지 보고서] 인공지능의 편향성(bias)을 해결하기 위한 방법\n",
      "\n",
      "MGI-Tackling-bias-in-AI-June-2019.pdf\n",
      "\n",
      "파일 다운로드\n",
      "\n",
      "<인공지능 경계선: 인공지능 및 사람들의 편견(Notes from the AI frontier: Tackling bias in AI (and in humans))>에서는 알고리즘이 사람들의 편견으로 발생한 불공정한 차이를 줄이는 데 도움을 줄 수 있는 곳과 인공지능으로 인해 확장될 수 있는 불공정한 편견을 비판적으로 분석하기 위한 개요를 보여준다.\n",
      "\n",
      "​\n",
      "\n",
      "​...\n",
      "---\n",
      "\n",
      "**[2. BIAS - Issue]**\n",
      "- **출처:** https://dailyan.com/news/article.html?no=731402 (URL: N/A)\n",
      "- **가중치:** 0.2\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 편향된 학습 데이터로 인해 차별적 결과를 초래할 수 있으며, 이는 사회적 불평등을 심화시킬 위험이 있다. 또한, AI의 결정에 대한 책임 소재가 불명확하여 법적 및 윤리적 혼란을 야기할 수 있다. 따라서 윤리적 고려와 투명성을 강화하고, 명확한 기준을 마련하는 것이 필수적이다.\n",
      "- **원문 일부:** > [이슈: issue] AI 개발의 윤리적 문제점 심화: 책임 소재와 편향성 논란 확대\n",
      "\n",
      "페이스북\n",
      " 엑스\n",
      " 카카오톡\n",
      " 네이버블로그\n",
      "\n",
      "### 급속한 AI 발전 속에서 윤리적 문제가 사회적 논쟁으로 확대되는 현황 분석\n",
      "\n",
      "데일리연합 (SNSJTV. 타임즈M) 김민제 기자 | 최근 급속도로 발전하는 인공지능(AI) 기술은 편리함과 효율성을 제공하지만 동시에 심각한 윤리적 문제를 야기한다는 우려가 커지고 있다.\n",
      "\n",
      "AI 개발 과정에서 발생하는 편향성 문제는 심각한 사회적 불평등을 초래할 수 있다. AI 알고리즘은 학습 데이터에 의존하는데, 이 ...\n",
      "---\n",
      "\n",
      "**[3. PRIVACY - Issue]**\n",
      "- **출처:** https://ovic.vic.gov.au/privacy/resources-for-organisations/artificial-intelligence-and-privacy-issues-and-challenges/ (URL: N/A)\n",
      "- **가중치:** 0.2\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 개발자의 개인적 편향이 시스템에 반영될 위험이 있으며, 이는 차별을 초래할 수 있습니다. 또한, AI의 불투명한 결과는 정부 기관의 의사결정에 부정적인 영향을 미칠 수 있습니다. 따라서 개인정보 보호와 차별 방지의 균형을 재조명할 필요가 있습니다.\n",
      "- **원문 일부:** > [이슈: issue] Artificial Intelligence and Privacy – Issues and Challenges\n",
      "\n",
      "Further, those building the systems may unknowingly introduce their own human biases into the functionality. Because AI challenges the ability of information privacy to operate as it has done historically, the safeguard against...\n",
      "---\n",
      "\n",
      "**[4. PRIVACY - Issue]**\n",
      "- **출처:** https://ovic.vic.gov.au/privacy/resources-for-organisations/artificial-intelligence-and-privacy-issues-and-challenges/ (URL: N/A)\n",
      "- **가중치:** 0.2\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 개발자의 개인적 편향이 시스템에 반영될 위험이 있으며, 이는 차별을 초래할 수 있습니다. 또한, AI의 불투명한 결과는 정부 기관의 의사결정에 부정적인 영향을 미칠 수 있습니다. 따라서 개인정보 보호와 차별 방지의 균형을 재검토할 필요성이 있습니다.\n",
      "- **원문 일부:** > [이슈: issue] Artificial Intelligence and Privacy – Issues and Challenges\n",
      "\n",
      "Further, those building the systems may unknowingly introduce their own human biases into the functionality. Because AI challenges the ability of information privacy to operate as it has done historically, the safeguard against...\n",
      "---\n",
      "\n",
      "**[5. TRANSPARENCY - Issue]**\n",
      "- **출처:** https://www.trustpath.ai/blog/ai-transparency-what-it-is-and-why-it-matters-for-compliance (URL: N/A)\n",
      "- **가중치:** 0.2\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 투명성을 유지하면서도 지적 재산 보호를 고려해야 하며, 의사결정 과정과 데이터 사용을 명확히 설명해야 합니다. 그러나 시스템의 세부 기술을 공개할 경우 보안 위험이 증가하고, 악의적인 사용자가 시스템을 우회할 수 있는 기회를 제공할 수 있습니다. 따라서 윤리적이고 안전한 결과를 보장하기 위해서는 투명성과 보안을 동시에 고려한 프레임워크가 필요합니다.\n",
      "- **원문 일부:** > [이슈: issue] AI transparency: What it is and why it matters for compliance?\n",
      "\n",
      "To balance transparency in AI with IP protection, businesses should focus on communicating key insights—like how decisions are made or what data is used—without revealing the specific technical blueprints. This approach ensu...\n",
      "---\n",
      "\n",
      "**[6. TRANSPARENCY - Issue]**\n",
      "- **출처:** https://www.trustpath.ai/blog/ai-transparency-what-it-is-and-why-it-matters-for-compliance (URL: N/A)\n",
      "- **가중치:** 0.2\n",
      "- **핵심 요약:** > AI 서비스 이력서 분석 추천 시스템은 투명성을 유지하면서도 지적 재산 보호를 고려해야 하며, 결정 과정과 데이터 사용을 명확히 설명해야 합니다. 그러나 이러한 투명성이 보안 위험을 초래할 수 있으며, 악의적인 사용자가 시스템을 우회할 수 있는 기회를 제공할 수 있습니다. 따라서 윤리적이고 안전한 결과를 보장하기 위해서는 투명성과 보안을 동시에 고려한 프레임워크가 필요합니다.\n",
      "- **원문 일부:** > [이슈: issue] AI transparency: What it is and why it matters for compliance?\n",
      "\n",
      "To balance transparency in AI with IP protection, businesses should focus on communicating key insights—like how decisions are made or what data is used—without revealing the specific technical blueprints. This approach ensu...\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 💻 3. 전체 데이터 JSON 형식 (Risk Assessor 수신 형태)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"이력서 분석 추천 시스템\",\n",
      "  \"weights\": {\n",
      "    \"baseline\": 0.8,\n",
      "    \"issue\": 0.2\n",
      "  },\n",
      "  \"scores\": {\n",
      "    \"bias\": 1.0,\n",
      "    \"privacy\": 1.0,\n",
      "    \"transparency\": 1.0\n",
      "  },\n",
      "  \"baseline_sources\": [\n",
      "    {\n",
      "      \"category\": \"bias\",\n",
      "      \"document_type\": \"baseline\",\n",
      "      \"source\": \"UNESCO_Ethics_2021.pdf\",\n",
      "      \"chunk_info\": \"(페이지 40의 내용)\",\n",
      "      \"score\": 0.8,\n",
      "      \"summary\": \"AI 서비스 이력서 분석 추천 시스템은 UNESCO의 정책 권고사항에 따라 윤리적 기준을 준수해야 하며, 이를 위해 경험 공유 메커니즘과 AI 규제 샌드박스가 필요하다. 이러한 도구들은 AI 관련 주체들이 윤리 리스크를 평가하고 관리하는 데 도움을 줄 수 있다. 따라서 시스템의 설계와 운영에서 윤리적 고려가 필수적이다.\",\n",
      "      \"content_excerpt\": \"across UNESCO’s areas of competence, an experience-\\nsharing mechanism, AI regulatory sandboxes, and an \\nassessment guide for all AI actors to evaluate their \\nadherence to policy recommendations mentioned in \\nthis document....\",\n",
      "      \"full_content\": \"across UNESCO’s areas of competence, an experience-\\nsharing mechanism, AI regulatory sandboxes, and an \\nassessment guide for all AI actors to evaluate their \\nadherence to policy recommendations mentioned in \\nthis document.\"\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"bias\",\n",
      "      \"document_type\": \"baseline\",\n",
      "      \"source\": \"EU_AI_Act.pdf\",\n",
      "      \"chunk_info\": \"(페이지 14의 내용)\",\n",
      "      \"score\": 0.8,\n",
      "      \"summary\": \"AI 서비스 이력서 분석 추천 시스템은 시장에 출시되기 전에 윤리적 평가 문서를 작성하고, 이를 국가 당국에 제공해야 하며, EU 데이터베이스에 등록해야 하는 의무가 있다. 이러한 규정은 시스템의 윤리적 리스크를 관리하고 투명성을 확보하기 위한 것이다. 따라서, 해당 시스템의 개발 및 운영 시 철저한 윤리적 검토가 필수적이다.\",\n",
      "      \"content_excerpt\": \"to above should draw up documentation of the assessment before that system is placed on the market or put into \\nservice and should provide that documentation to national competent authorities upon request. Such a provider \\nshould be obliged to register the AI system in the EU database established un...\",\n",
      "      \"full_content\": \"to above should draw up documentation of the assessment before that system is placed on the market or put into \\nservice and should provide that documentation to national competent authorities upon request. Suc\n",
      "...\n",
      "[전체 JSON 데이터가 너무 길어 일부만 표시됩니다.]\n"
     ]
    }
   ],
   "source": [
    "# evidence_collector.ipynb의 마지막 셀에 추가하여 실행\n",
    "\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# evidence_result 변수가 collect_evidence(test_service_profile) 실행 후 저장된 상태여야 합니다.\n",
    "if 'evidence_result' in locals():\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # 📊 Risk Assessor 전달 데이터 최종 출력 및 확인\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    display(Markdown(\"## 🚀 Risk Assessor 에이전트 전달 내용 최종 확인\"))\n",
    "    \n",
    "    # 1. 메타 정보 출력\n",
    "    print(f\"서비스명: {evidence_result['query']}\")\n",
    "    print(f\"가중치: Baseline {evidence_result['weights']['baseline']} : Issue {evidence_result['weights']['issue']}\")\n",
    "    print(f\"수집된 리스크 카테고리: {list(evidence_result['scores'].keys())}\")\n",
    "    print(f\"총 전달 증거 개수: {len(evidence_result['baseline_sources']) + len(evidence_result['issue_sources'])}개\\n\")\n",
    "\n",
    "    # 2. Baseline 증거 상세 출력\n",
    "    display(Markdown(\"### 📚 1. Baseline 증거 (법적/윤리 기준 근거)\"))\n",
    "    if evidence_result['baseline_sources']:\n",
    "        for i, src in enumerate(evidence_result['baseline_sources']):\n",
    "            category = src['category'].upper()\n",
    "            \n",
    "            # Risk Assessor가 가장 먼저 보게 될 핵심 정보 출력\n",
    "            output = f\"\"\"\n",
    "**[{i+1}. {category} - Baseline]**\n",
    "- **출처:** {src['source']} {src['chunk_info']}\n",
    "- **가중치:** {src['score']:.1f}\n",
    "- **핵심 요약:** > {src['summary']}\n",
    "- **원문 일부:** > {src['content_excerpt']}\n",
    "---\"\"\"\n",
    "            print(output)\n",
    "    else:\n",
    "        print(\"수집된 Baseline 증거가 없습니다.\")\n",
    "\n",
    "    # 3. Issue 증거 상세 출력\n",
    "    display(Markdown(\"### 📰 2. Issue 증거 (최신 사회적 반응 근거)\"))\n",
    "    if evidence_result['issue_sources']:\n",
    "        for i, src in enumerate(evidence_result['issue_sources']):\n",
    "            category = src['category'].upper()\n",
    "            \n",
    "            # Risk Assessor가 가장 먼저 보게 될 핵심 정보 출력\n",
    "            output = f\"\"\"\n",
    "**[{i+1}. {category} - Issue]**\n",
    "- **출처:** {src['source']} (URL: {src.get('url', 'N/A')})\n",
    "- **가중치:** {src['score']:.1f}\n",
    "- **핵심 요약:** > {src['summary']}\n",
    "- **원문 일부:** > {src['content_excerpt']}\n",
    "---\"\"\"\n",
    "            print(output)\n",
    "    else:\n",
    "        print(\"수집된 Issue 증거가 없습니다.\")\n",
    "\n",
    "    # 4. 전체 데이터 JSON 형식으로 출력 (Risk Assessor가 코드로 받는 형태)\n",
    "    display(Markdown(\"### 💻 3. 전체 데이터 JSON 형식 (Risk Assessor 수신 형태)\"))\n",
    "    # 전체 딕셔너리를 JSON 문자열로 변환하여 출력\n",
    "    # (주의: 내용이 매우 길어질 수 있으므로, 실제 환경에서는 파일로 저장하거나 일부만 출력할 수 있음)\n",
    "    full_json_output = json.dumps(evidence_result, indent=2, ensure_ascii=False)\n",
    "    print(full_json_output[:2000] + \"\\n...\\n[전체 JSON 데이터가 너무 길어 일부만 표시됩니다.]\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ 'evidence_result' 변수를 찾을 수 없습니다. 'step8. 테스트 실행'을 먼저 실행해주세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-JIaWGMA_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

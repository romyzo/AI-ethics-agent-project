{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "\n",
        "# ğŸ‘©â€ğŸ’» Author    : Hyelim Jo\n",
        "# ğŸ¯ Purpose   : AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ v1.0\n",
        "# ğŸ“… Created   : 2025-10-22\n",
        "# ğŸ“œ Note      : service_profiler.ipynb\n",
        "\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------- Update Log ----------------------------------\n",
        "\n",
        "# 2025-10-22 14:00 / ì´ˆê¸° ìƒì„± / Service Profiler ê¸°ë³¸ êµ¬ì¡° êµ¬í˜„\n",
        "# 2025-10-22 15:30 / API í‚¤ ì˜¤ë¥˜ í•´ê²° / load_dotenv() ì¶”ê°€\n",
        "\n",
        "# ------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# step1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from typing import Dict, Any\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
        "load_dotenv()\n",
        "\n",
        "print(\"[OK] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] í”„ë¡¬í”„íŠ¸ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# step2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (í‚¤ ì´ë¦„ ë³€ê²½: data_handling_method, user_impact_scope, diagnosed_risk_categories)\n",
        "prompt_template = \"\"\"ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì£¼ì–´ì§„ AI ì„œë¹„ìŠ¤ ì„¤ëª…ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "# ì„œë¹„ìŠ¤ ì„¤ëª…:\n",
        "{service_description}\n",
        "\n",
        "# ì¶”ì¶œí•  ì •ë³´:\n",
        "1. service_name: ì„œë¹„ìŠ¤ ì´ë¦„\n",
        "2. service_type: ì„œë¹„ìŠ¤ ìœ í˜• (recommendation, classification, prediction ë“± ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ ì„ íƒ)\n",
        "3. description: í•µì‹¬ ì„¤ëª… (1-2ë¬¸ì¥)\n",
        "4. data_handling_method: ì²˜ë¦¬í•˜ëŠ” ë°ì´í„° ë° ì²˜ë¦¬ ë°©ì‹ (ìµœì¢… ë³´ê³ ì„œì˜ 'ë°ì´í„° ì²˜ë¦¬ ë°©ì‹' í•­ëª©ì— í•´ë‹¹)\n",
        "5. user_impact_scope: ì‚¬ìš©ì ì˜í–¥ ë²”ìœ„ (ìµœì¢… ë³´ê³ ì„œì˜ 'ì‚¬ìš©ì ì˜í–¥ ë²”ìœ„' í•­ëª©ì— í•´ë‹¹)\n",
        "6. diagnosed_risk_categories: ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬ (bias, privacy, transparency, accountability, safety, security ì¤‘ ì„ íƒ, ë°°ì—´)\n",
        "\n",
        "JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "print(\"[OK] í”„ë¡¬í”„íŠ¸ ì •ì˜ ì™„ë£Œ\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Chain êµ¬ì„± ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# step3. LLM ë° Chain ì„¤ì •\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "json_parser = JsonOutputParser()\n",
        "chain = prompt | llm | json_parser\n",
        "\n",
        "print(\"[OK] Chain êµ¬ì„± ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# step4. Service Profiler í•¨ìˆ˜ ì •ì˜\n",
        "def service_profiler(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"ì„œë¹„ìŠ¤ í”„ë¡œíŒŒì¼ ìƒì„±\"\"\"\n",
        "    service_description = state.get(\"service_description\", \"\")\n",
        "    \n",
        "    # ğŸ’¡ LLM í˜¸ì¶œ ì‹œë„\n",
        "    try:\n",
        "        result = chain.invoke({\"service_description\": service_description})\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜\n",
        "        result = {\n",
        "            \"service_name\": \"N/A\",\n",
        "            \"service_type\": \"N/A\",\n",
        "            \"description\": \"LLM í˜¸ì¶œ ì‹¤íŒ¨ë¡œ í”„ë¡œíŒŒì¼ ìƒì„± ë¶ˆê°€\",\n",
        "            \"data_handling_method\": \"N/A\",\n",
        "            \"user_impact_scope\": \"N/A\",\n",
        "            \"diagnosed_risk_categories\": []\n",
        "        }\n",
        "\n",
        "    # Stateì— ê²°ê³¼ ì €ì¥\n",
        "    state[\"service_profile\"] = result\n",
        "    \n",
        "    print(f\"[OK] í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ - {result.get('service_name')} ({result.get('service_type')})\")\n",
        "    return state\n",
        "\n",
        "print(\"[OK] í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ - ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ (recommendation)\n",
            "\n",
            "[ê²°ê³¼]\n",
            "ì„œë¹„ìŠ¤ëª…: ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
            "ì„œë¹„ìŠ¤ ìœ í˜•: recommendation\n",
            "ë°ì´í„° ì²˜ë¦¬ ë°©ì‹: ê°œì¸ ì‹ë³„ ì •ë³´ëŠ” ìµëª…í™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
            "ì‚¬ìš©ì ì˜í–¥ ë²”ìœ„: ì±„ìš© ê³¼ì •ì—ì„œ ì§€ì›ìì™€ ê¸°ì—… ëª¨ë‘ì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n",
            "ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: bias, privacy, transparency\n",
            "\n",
            "ì „ì²´ í”„ë¡œíŒŒì¼:\n",
            "{'service_name': 'ì´ë ¥ì„œ ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ', 'service_type': 'recommendation', 'description': 'ì±„ìš© ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬ ì í•©í•œ í›„ë³´ìë¥¼ ì¶”ì²œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. í•™ë ¥, ê²½ë ¥, ìê²©ì¦ì„ ë°”íƒ•ìœ¼ë¡œ ì§ë¬´ ì í•©ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.', 'data_handling_method': 'ê°œì¸ ì‹ë³„ ì •ë³´ëŠ” ìµëª…í™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.', 'user_impact_scope': 'ì±„ìš© ê³¼ì •ì—ì„œ ì§€ì›ìì™€ ê¸°ì—… ëª¨ë‘ì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.', 'diagnosed_risk_categories': ['bias', 'privacy', 'transparency']}\n"
          ]
        }
      ],
      "source": [
        "# step5. í…ŒìŠ¤íŠ¸\n",
        "test_state = {\n",
        "    \"service_description\": \"ì±„ìš© ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬ ì í•©í•œ í›„ë³´ìë¥¼ ì¶”ì²œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. í•™ë ¥, ê²½ë ¥, ìê²©ì¦ì„ ë°”íƒ•ìœ¼ë¡œ ì§ë¬´ ì í•©ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ê°œì¸ ì‹ë³„ ì •ë³´ëŠ” ìµëª…í™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.\",\n",
        "    \"service_profile\": {}\n",
        "}\n",
        "\n",
        "result_state = service_profiler(test_state)\n",
        "\n",
        "print(\"\\n[ê²°ê³¼]\")\n",
        "print(\"ì„œë¹„ìŠ¤ëª…:\", result_state[\"service_profile\"].get(\"service_name\"))\n",
        "print(\"ì„œë¹„ìŠ¤ ìœ í˜•:\", result_state[\"service_profile\"].get(\"service_type\"))\n",
        "print(\"ë°ì´í„° ì²˜ë¦¬ ë°©ì‹:\", result_state[\"service_profile\"].get(\"data_handling_method\")) # ë³€ê²½ëœ í‚¤\n",
        "print(\"ì‚¬ìš©ì ì˜í–¥ ë²”ìœ„:\", result_state[\"service_profile\"].get(\"user_impact_scope\"))     # ë³€ê²½ëœ í‚¤\n",
        "print(\"ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬:\", \", \".join(result_state[\"service_profile\"].get(\"diagnosed_risk_categories\", []))) # ë³€ê²½ëœ í‚¤\n",
        "print(\"\\nì „ì²´ í”„ë¡œíŒŒì¼:\")\n",
        "print(result_state[\"service_profile\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# step6. State ê¸°ë°˜ ì‹¤í–‰ í•¨ìˆ˜ ì •ì˜\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from state_manager import load_state, save_state, update_status\n",
        "\n",
        "def service_profiler_execute(service_description: str):\n",
        "    \"\"\"Service Profiler ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ” Service Profiler ì‹œì‘...\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # State ë¡œë“œ\n",
        "    state = load_state()\n",
        "    \n",
        "    # ì„œë¹„ìŠ¤ ì„¤ëª… ì„¤ì •\n",
        "    state[\"service_description\"] = service_description\n",
        "    \n",
        "    # ì„œë¹„ìŠ¤ í”„ë¡œíŒŒì¼ ìƒì„±\n",
        "    result = chain.invoke({\"service_description\": service_description})\n",
        "    state[\"service_profile\"] = result\n",
        "    \n",
        "    # State ì €ì¥\n",
        "    save_state(state)\n",
        "    update_status(state, \"service_profiler\", \"completed\")\n",
        "    \n",
        "    print(f\"âœ… í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ - {result.get('service_name')} ({result.get('service_type')})\")\n",
        "    print(f\"âœ… ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬: {', '.join(result.get('risk_categories', []))}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"âœ… Service Profiler ì‹¤í–‰ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-kr-JIaWGMA_-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

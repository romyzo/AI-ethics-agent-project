#!/usr/bin/env python3
"""
Report Composer Agent - Python Version (Markdown â†’ PDF ìë™ ë³€í™˜ í¬í•¨)
ìµœì¢… AI ìœ¤ë¦¬ ì§„ë‹¨ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  PDFë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
from datetime import date
from typing import Dict, Any, List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import pypandoc

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ---------------------------------------------------------
# 1ï¸âƒ£ ì‹¤í–‰ í•¨ìˆ˜ (Supervisor í˜¸ì¶œ)
# ---------------------------------------------------------
def report_composer_execute():
    """Report Composer ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "=" * 60)
    print("ğŸ“ Report Composer ì‹œì‘...")
    print("=" * 60)

    sys.path.append("..")
    from state_manager import load_state, save_state, update_status, save_report_to_file

    state = load_state()

    # Mitigation Recommender ê²°ê³¼ í™•ì¸
    if state.get("status", {}).get("mitigation_recommender") != "completed":
        print("âŒ Mitigation Recommenderê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return state

    # ë³´ê³ ì„œ ìƒì„±
    updated_state = compose_report_and_update_state(state)

    # Markdown íŒŒì¼ ì €ì¥
    service_name = (
        updated_state.get("service_profile", {}).get("service_name", "AI_Service")
    )
    report_content = updated_state.get("final_report_markdown", "")

    if not report_content:
        print("âŒ Markdown ë³´ê³ ì„œ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. PDF ë³€í™˜ ë¶ˆê°€.")
        return updated_state

    md_path = save_report_to_file(report_content, service_name)

    # PDF ë³€í™˜ ìˆ˜í–‰
    pdf_path = convert_markdown_to_pdf(md_path)

    # Stateì— ì €ì¥
    updated_state["report_file_path"] = md_path
    updated_state["report_pdf_path"] = pdf_path

    # ìƒíƒœ ì €ì¥
    save_state(updated_state)
    update_status(updated_state, "report_composer", "completed")

    print(f"âœ… Markdown ë° PDF ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ!\nğŸ“„ {pdf_path}")
    return updated_state


# ---------------------------------------------------------
# 2ï¸âƒ£ ë³´ê³ ì„œ ì‘ì„± í•¨ìˆ˜ (LLM í˜¸ì¶œ)
# ---------------------------------------------------------
def compose_report_and_update_state(state: Dict[str, Any]) -> Dict[str, Any]:
    """Stateì˜ ëª¨ë“  ì •ë³´ë¥¼ ì·¨í•©í•˜ì—¬ ìµœì¢… Markdown ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  Stateì— ì €ì¥í•©ë‹ˆë‹¤."""

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)

    # state.py êµ¬ì¡°ì— ë§ê²Œ key ì´ë¦„ í†µì¼
    service_profile = state.get("service_profile", {})
    risk_assessment = state.get("assessment_result", {})
    recommendations = state.get("recommendation_result", [])
    collected_evidence = state.get("evidence_data", {})

    # í•„ìˆ˜ ë°ì´í„° ê²€ì‚¬
    if not all([service_profile, risk_assessment, recommendations, collected_evidence]):
        print("âŒ Stateì— í•„ìˆ˜ ë°ì´í„°(Profile, Evidence, Assessment, Recommendation)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        state["report_status"] = "Error: Missing upstream data."
        return state

    print("ğŸ§  Report Composer: LLM ê¸°ë°˜ Markdown ìƒì„± ì¤‘...")

    # ì¦ê±° ë¦¬ìŠ¤íŠ¸ ì •ë¦¬
    evidences_summary = []
    if collected_evidence:
        # baseline_sourcesì™€ issue_sourcesë¥¼ í•©ì³ì„œ ì²˜ë¦¬
        baseline_sources = collected_evidence.get("baseline_sources", [])
        issue_sources = collected_evidence.get("issue_sources", [])
        
        for e in baseline_sources + issue_sources:
            evidences_summary.append({
                "source": e.get("source", "N/A"),
                "category": e.get("category", "ê¸°íƒ€"),
                "summary": e.get("summary", ""),
            })

    # í”„ë¡¬í”„íŠ¸ ì •ì˜
    REPORT_PROMPT = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ì§„ë‹¨ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                "ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™„ì „í•œ Markdown ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. "
                "ì¶”ê°€ ì„¤ëª… ì—†ì´ ìˆœìˆ˜ Markdown í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
                "[ë³´ê³ ì„œ ëª©ì°¨]:\n"
                "1. EXECUTIVE SUMMARY\n"
                "2. SERVICE PROFILE\n"
                "3. RISK ASSESSMENT\n"
                "4. MITIGATION RECOMMENDATIONS\n"
                "5. CONCLUSION\n"
                "6. REFERENCE\n"
                "7. APPENDIX"
            ),
            (
                "human",
                "--- ìµœì¢… ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ---"
                "\nì‘ì„±ì¼: {today_date}"
                "\n\n[ì„œë¹„ìŠ¤ í”„ë¡œíŒŒì¼]\n{service_profile}"
                "\n\n[ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼]\n{risk_assessment}"
                "\n\n[ê°œì„  ê¶Œê³ ì•ˆ]\n{recommendations}"
                "\n\n[ìˆ˜ì§‘ëœ ì¦ê±°]\n{evidences_summary}"
            ),
        ]
    )

    chain = REPORT_PROMPT | llm

    try:
        final_report_markdown = chain.invoke(
            {
                "today_date": date.today().isoformat(),
                "service_profile": json.dumps(
                    service_profile, indent=2, ensure_ascii=False
                ),
                "risk_assessment": json.dumps(
                    risk_assessment, indent=2, ensure_ascii=False
                ),
                "recommendations": json.dumps(
                    recommendations, indent=2, ensure_ascii=False
                ),
                "evidences_summary": json.dumps(
                    evidences_summary, indent=2, ensure_ascii=False
                ),
            }
        ).content
    except Exception as e:
        final_report_markdown = f"## âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨\n\nLLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        state["report_status"] = "Error generating report."
        return state

    # State ì €ì¥
    state["final_report_markdown"] = final_report_markdown
    state["report_status"] = "Success"
    print("âœ… Report Composer ì™„ë£Œ ë° State ì—…ë°ì´íŠ¸ ì™„ë£Œ!\n")
    return state


# ---------------------------------------------------------
# 3ï¸âƒ£ Markdown â†’ PDF ë³€í™˜ í•¨ìˆ˜
# ---------------------------------------------------------



def convert_markdown_to_pdf(md_path: str) -> str:
    """ìƒì„±ëœ Markdown ë³´ê³ ì„œë¥¼ PDFë¡œ ìë™ ë³€í™˜ (wkhtmltopdf ì—”ì§„ ì‚¬ìš©)"""
    try:
        pdf_path = md_path.replace(".md", ".pdf")
        pypandoc.convert_text(
            open(md_path, "r", encoding="utf-8").read(),
            "pdf",
            format="md",
            outputfile=pdf_path,
            extra_args=["--standalone", "--pdf-engine=wkhtmltopdf"],
        )
        print(f"ğŸ“„ PDF ë³€í™˜ ì™„ë£Œ: {pdf_path}")
        return pdf_path
    except Exception as e:
        print(f"âš ï¸ PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
        return ""

# ---------------------------------------------------------
# 4ï¸âƒ£ ë‹¨ë… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# ---------------------------------------------------------
if __name__ == "__main__":
    report_composer_execute()
